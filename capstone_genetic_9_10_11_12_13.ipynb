{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gUnROAJ9VSF5",
        "outputId": "4c2db36a-64cb-4876-f294-d242f4e6a22e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Function_Catalogue_Round_8_ExactStructure.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3af998ca3f6e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Function_Catalogue_Round_8_ExactStructure.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Preview the structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Function_Catalogue_Round_8_ExactStructure.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(\"/content/Function_Catalogue_Round_8_ExactStructure.csv\")\n",
        "\n",
        "# Preview the structure\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W86sCpmtWD2X"
      },
      "outputs": [],
      "source": [
        "# Display column names\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Remove leading/trailing spaces if necessary\n",
        "df.columns = df.columns.str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K-8MgM9bWJWr"
      },
      "outputs": [],
      "source": [
        "# Unique functions and themes\n",
        "print(\"Unique Functions:\", df['Function'].unique())\n",
        "print(\"Unique Themes:\", df['Theme'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w3GLqlS3WRD-"
      },
      "outputs": [],
      "source": [
        "# Missing data\n",
        "missing_summary = df.isnull().sum()\n",
        "print(\"Missing values per column:\\n\", missing_summary)\n",
        "\n",
        "# View samples with missing values\n",
        "df[df.isnull().any(axis=1)].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4wLLk0b3Walp"
      },
      "outputs": [],
      "source": [
        "# Show sample InputVec values\n",
        "df['InputVec'].head(10).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "50m9Gd1NWiA-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def parse_inputvec(vec):\n",
        "    try:\n",
        "        # Handle dash-separated simple format: \"0.123-0.456\"\n",
        "        if '-' in vec and 'array' not in vec and '[' not in vec:\n",
        "            parts = vec.split('-')\n",
        "            return float(parts[0]), float(parts[1])\n",
        "        # Handle formats like: \"[np.float64(...), np.float64(...)]\"\n",
        "        nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+e[-+]?\\d+\", vec)\n",
        "        if len(nums) >= 2:\n",
        "            return float(nums[0]), float(nums[1])\n",
        "        else:\n",
        "            return np.nan, np.nan\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "# Apply the parser\n",
        "df[['x1', 'x2']] = df['InputVec'].apply(lambda x: pd.Series(parse_inputvec(str(x))))\n",
        "\n",
        "# Convert Score to numeric safely\n",
        "df['Score'] = pd.to_numeric(df['Score'], errors='coerce')\n",
        "\n",
        "# Show cleaned output\n",
        "df[['InputVec', 'x1', 'x2', 'Score']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UG0UAFPWWwbs"
      },
      "outputs": [],
      "source": [
        "df.sort_values('Score', ascending=True).head(10)  # lowest score = best?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3I-rkCZlWyhl"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=df, x='x1', y='x2', hue='Score', palette='coolwarm')\n",
        "plt.title(\"Function Landscape: InputVec vs Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZyzNQO8sW-8N"
      },
      "outputs": [],
      "source": [
        "def parse_vec_general(vec):\n",
        "    try:\n",
        "        nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+e[-+]?\\d+\", str(vec))\n",
        "        floats = [float(n) for n in nums]\n",
        "        while len(floats) < 4:  # pad short vectors\n",
        "            floats.append(np.nan)\n",
        "        return pd.Series(floats[:4], index=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
        "    except:\n",
        "        return pd.Series([np.nan, np.nan, np.nan, np.nan], index=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
        "\n",
        "# Apply to all InputVec\n",
        "df[['x1', 'x2', 'x3', 'x4']] = df['InputVec'].apply(parse_vec_general)\n",
        "\n",
        "# Confirm parsing worked\n",
        "df[['InputVec', 'x1', 'x2', 'x3', 'x4']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v8lI1ArEXC3z"
      },
      "outputs": [],
      "source": [
        "# Focus only on F4\n",
        "f4 = df[df['Function'] == 'F4']\n",
        "\n",
        "# 3D visualization (first 3 dimensions)\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "p = ax.scatter(f4['x1'], f4['x2'], f4['x3'], c=f4['Score'], cmap='coolwarm')\n",
        "ax.set_title('F4 Function - First 3 Dimensions')\n",
        "ax.set_xlabel('x1')\n",
        "ax.set_ylabel('x2')\n",
        "ax.set_zlabel('x3')\n",
        "fig.colorbar(p)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nlauuUiCYDrX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import random\n",
        "\n",
        "# Filter data for F4 and drop NaNs\n",
        "f4_df = df[df['Function'] == 'F4'].dropna(subset=['x1', 'x2', 'x3', 'x4', 'Score'])\n",
        "\n",
        "# Prepare data for model\n",
        "X = f4_df[['x1', 'x2', 'x3', 'x4']].values\n",
        "y = f4_df['Score'].values\n",
        "\n",
        "# Invert score since GA maximizes by default\n",
        "y = -y\n",
        "\n",
        "# Train a GP surrogate to guide fitness evaluation\n",
        "kernel = RBF()\n",
        "gp = GaussianProcessRegressor(kernel=kernel)\n",
        "gp.fit(X, y)\n",
        "\n",
        "# --- Genetic Algorithm Settings ---\n",
        "POP_SIZE = 50\n",
        "N_GEN = 20\n",
        "N_ELITE = 10\n",
        "MUTATION_RATE = 0.1\n",
        "\n",
        "def random_candidate():\n",
        "    return np.random.uniform(0, 1, 4)\n",
        "\n",
        "def mutate(vec):\n",
        "    return np.clip(vec + np.random.normal(0, 0.05, size=4), 0, 1)\n",
        "\n",
        "def crossover(p1, p2):\n",
        "    alpha = np.random.rand()\n",
        "    return np.clip(alpha * p1 + (1 - alpha) * p2, 0, 1)\n",
        "\n",
        "def fitness(cand):\n",
        "    return -gp.predict(cand.reshape(1, -1))[0]  # Negative because original scores are negative\n",
        "\n",
        "# --- Initialize population ---\n",
        "population = np.array([random_candidate() for _ in range(POP_SIZE)])\n",
        "\n",
        "for gen in range(N_GEN):\n",
        "    scores = np.array([fitness(ind) for ind in population])\n",
        "    elite_indices = scores.argsort()[:N_ELITE]\n",
        "    elite = population[elite_indices]\n",
        "\n",
        "    new_population = elite.tolist()\n",
        "    while len(new_population) < POP_SIZE:\n",
        "        parents = random.sample(list(elite), 2)\n",
        "        child = crossover(parents[0], parents[1])\n",
        "        if np.random.rand() < MUTATION_RATE:\n",
        "            child = mutate(child)\n",
        "        new_population.append(child)\n",
        "\n",
        "    population = np.array(new_population)\n",
        "\n",
        "# --- Output Top Candidates ---\n",
        "final_scores = [fitness(ind) for ind in population]\n",
        "top_indices = np.argsort(final_scores)[:10]\n",
        "top_candidates = population[top_indices]\n",
        "\n",
        "# Display top 10 new vectors\n",
        "import pandas as pd\n",
        "best_f4_vectors = pd.DataFrame(top_candidates, columns=['x1', 'x2', 'x3', 'x4'])\n",
        "print(best_f4_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bnq0AGoHYL0-"
      },
      "outputs": [],
      "source": [
        "# Convert to dash-separated InputVec format\n",
        "best_f4_vectors['InputVec'] = best_f4_vectors.apply(lambda row:\n",
        "    f\"{row['x1']:.6f}-{row['x2']:.6f}-{row['x3']:.6f}-{row['x4']:.6f}\", axis=1)\n",
        "\n",
        "# Add function metadata\n",
        "best_f4_vectors['Function'] = 'F4'\n",
        "best_f4_vectors['Theme'] = 'Fast, but Inaccurate Modelling'\n",
        "best_f4_vectors['Score'] = ''  # placeholder until scored\n",
        "\n",
        "# Rearrange columns\n",
        "submission_ready = best_f4_vectors[['Function', 'Theme', 'InputVec', 'Score']]\n",
        "\n",
        "# Export\n",
        "submission_ready.to_csv(\"F4_GA_Submission_Round9.csv\", index=False)\n",
        "submission_ready.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C6aYcbGSYX4p"
      },
      "outputs": [],
      "source": [
        "# Manually define your selections — these should be filled with YOUR best vectors\n",
        "submission = pd.DataFrame([\n",
        "    {\"Function\": \"F1\", \"Theme\": \"Searching for Contamination Sources\", \"InputVec\": \"0.574329-0.879898\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F2\", \"Theme\": \"Optimising Noisy Models\", \"InputVec\": \"0.712000-0.489000\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F3\", \"Theme\": \"Drug Discovery Problem\", \"InputVec\": \"0.842310-0.512783\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F4\", \"Theme\": \"Fast, but Inaccurate Modelling\", \"InputVec\": \"0.726952-0.189810-0.835269-0.100856\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F5\", \"Theme\": \"Yield in a Chemical Reaction\", \"InputVec\": \"0.789315-0.734624\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F6\", \"Theme\": \"Cake and Stuff\", \"InputVec\": \"0.562398-0.627903\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F7\", \"Theme\": \"Sometimes Lazy is Best\", \"InputVec\": \"0.392748-0.682337\", \"Score\": \"\"},\n",
        "    {\"Function\": \"F8\", \"Theme\": \"High-dimensional Optimisation\", \"InputVec\": \"0.688905-0.968377\", \"Score\": \"\"}\n",
        "])\n",
        "\n",
        "# Export to CSV\n",
        "submission.to_csv(\"Round9_Full_Submission.csv\", index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bwddOGn4YqI_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual filename if different\n",
        "df = pd.read_csv(\"/content/Function_Catalogue_Round_8_ExactStructure.csv\")\n",
        "df.columns = df.columns.str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n5m9lj5IYsUo"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def parse_vec_general(vec):\n",
        "    try:\n",
        "        nums = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+e[-+]?\\d+\", str(vec))\n",
        "        floats = [float(n) for n in nums]\n",
        "        while len(floats) < 4:  # pad short vectors\n",
        "            floats.append(np.nan)\n",
        "        return pd.Series(floats[:4], index=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
        "    except:\n",
        "        return pd.Series([np.nan, np.nan, np.nan, np.nan], index=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
        "\n",
        "df[['x1', 'x2', 'x3', 'x4']] = df['InputVec'].apply(parse_vec_general)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Zn1LqtAYuJk"
      },
      "outputs": [],
      "source": [
        "# Filter Round 8 submissions\n",
        "round8_submissions = df[df['Theme'] == 'Submission Round 8']\n",
        "\n",
        "# Show function + InputVec for Round 8\n",
        "round8_summary = round8_submissions[['Function', 'InputVec']].dropna().reset_index(drop=True)\n",
        "round8_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "1ROrVo3KYxqi"
      },
      "outputs": [],
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=round8_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DP3mpse7b8yg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list of your submission vectors in order (F1 to F8)\n",
        "submission_vectors = [\n",
        "    \"0.574329-0.879898\",                                      # F1 (2D)\n",
        "    \"0.712000-0.489000\",                                      # F2 (2D)\n",
        "    \"0.842310-0.512783-0.335000\",                             # F3 (3D) ← make sure this is 3D\n",
        "    \"0.726952-0.189810-0.835269-0.100856\",                    # F4 (4D)\n",
        "    \"0.789315-0.734624-0.122222-0.444444\",                    # F5 (4D) ← expand to 5D if needed\n",
        "    \"0.562398-0.627903-0.300000-0.450000-0.123456\",           # F6 (5D)\n",
        "    \"0.392748-0.682337-0.400000-0.600000-0.250000-0.123000\",  # F7 (6D)\n",
        "    \"0.688905-0.968377-0.100000-0.200000-0.300000-0.400000-0.500000-0.600000\"  # F8 (8D)\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "submission_df = pd.DataFrame(submission_vectors, columns=[\"InputVec\"])\n",
        "\n",
        "# Export to CSV\n",
        "submission_df.to_csv(\"Capstone_Round9_Submission_Format.csv\", index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z2RvF9U5b_Xm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace these with your actual final vectors for F1 to F8\n",
        "submission_vectors = [\n",
        "    \"0.574329-0.879898\",                                      # F1 (2D)\n",
        "    \"0.712000-0.489000\",                                      # F2 (2D)\n",
        "    \"0.842310-0.512783-0.335000\",                             # F3 (3D)\n",
        "    \"0.726952-0.189810-0.835269-0.100856\",                    # F4 (4D)\n",
        "    \"0.789315-0.734624-0.122222-0.444444-0.311111\",           # F5 (5D)\n",
        "    \"0.562398-0.627903-0.300000-0.450000-0.123456\",           # F6 (5D)\n",
        "    \"0.392748-0.682337-0.400000-0.600000-0.250000-0.123000\",  # F7 (6D)\n",
        "    \"0.688905-0.968377-0.100000-0.200000-0.300000-0.400000-0.500000-0.600000\"  # F8 (8D)\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "submission_df = pd.DataFrame(submission_vectors, columns=[\"InputVec\"])\n",
        "\n",
        "# Preview the final submission\n",
        "print(\"✅ Your Round 9 Submission Format:\\n\")\n",
        "print(submission_df.to_string(index=False, header=False))\n",
        "\n",
        "# Save to CSV with no header or index\n",
        "submission_df.to_csv(\"Capstone_Round9_Submission_Format.csv\", index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FlTKQdxHlSVR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Embed your Round 9 queries and observations directly into the code\n",
        "queries = [\n",
        "    [0.944034, 0.625117],\n",
        "    [0.768771, 0.105777],\n",
        "    [0.1456, 0.944454, 0.638992],\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562],\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022],\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],\n",
        "    [0.25682, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776]\n",
        "]\n",
        "\n",
        "observations = [\n",
        "    [1.3276592050304897e-69, 0.27308818432797793, -0.10726379301566011, -20.949420794091107,\n",
        "     13.377756436400528, -1.1857272137575898, 0.023506147714804363, 8.3316420728934],\n",
        "    [6.933250699386668e-70, 0.09312933125476712, -0.15237863681921446, -22.018089179607596,\n",
        "     12.979330536136526, -1.1838236564336748, 0.023506147714804363, 8.434940976893401],\n",
        "    [6.933250699386668e-70, 0.23562706897099497, -0.14698930107649133, -22.018089179607596,\n",
        "     12.979330536136526, -1.263310156017569, 0.023506147714804363, 8.434940976893401],\n",
        "    [4.6015626100136584e-113, 0.33828687086483444, -0.11198066229665458, -20.949420794091107,\n",
        "     13.377756436400528, -1.0715940396376764, 0.007250474515368666, 8.434940976893401],\n",
        "    [4.6015626100136584e-113, 0.2358527631144813, -0.11658849810095136, -20.949420794091107,\n",
        "     13.377756436400528, -1.108280528164095, 0.007250474515368666, 8.434940976893401],\n",
        "    [4.6015626100136584e-113, 0.19467655335464928, -0.10701392790144047, -20.949420794091107,\n",
        "     13.377756436400528, -1.0802789662503398, 0.007250474515368666, 8.434940976893401],\n",
        "    [-6.3577541156068885e-86, 0.1094856197569318, -0.12400622516054445, -20.387612583330036,\n",
        "     13.377756436400528, -1.1219255105599752, 0.03872554610994976, 8.294127480893401],\n",
        "    [-6.3577541156068885e-86, 0.10969400967393614, -0.1271560099068078, -20.387612583330036,\n",
        "     13.377756436400528, -1.09808634927923, 0.03872554610994976, 8.294127480893401]\n",
        "]\n",
        "\n",
        "# Create a DataFrame for comparison\n",
        "comparison_data = []\n",
        "for i, (query, obs) in enumerate(zip(queries, observations)):\n",
        "    comparison_data.append({\n",
        "        'Query_Index': i+1,\n",
        "        'Query_Vector': query,\n",
        "        'Observation_Score_Vector': obs\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Save to CSV (optional, for your records)\n",
        "comparison_file = \"/content/Round9_Query_Observation_Comparison.csv\"\n",
        "df_comparison.to_csv(comparison_file, index=False)\n",
        "\n",
        "# Display the DataFrame in notebook\n",
        "df_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ig7-DnColxpK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import random\n",
        "\n",
        "# --- Step 1: Define your Round 9 queries and observations ---\n",
        "queries = [\n",
        "    [0.944034, 0.625117],  # F1 (2D)\n",
        "    [0.768771, 0.105777],  # F2 (2D)\n",
        "    [0.1456, 0.944454, 0.638992],  # F3 (3D)\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562],  # F4 (4D)\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022],  # F5 (4D)\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],  # F6 (5D)\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],  # F7 (6D)\n",
        "    [0.25682, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776]  # F8 (8D)\n",
        "]\n",
        "\n",
        "observations_scores = [\n",
        "    8.3316420728934,  # F1\n",
        "    8.434940976893401,  # F2\n",
        "    8.434940976893401,  # F3\n",
        "    8.434940976893401,  # F4\n",
        "    8.434940976893401,  # F5\n",
        "    8.434940976893401,  # F6\n",
        "    8.294127480893401,  # F7\n",
        "    8.294127480893401   # F8\n",
        "]\n",
        "\n",
        "# --- Step 2: Loop per function and apply GP + GA ---\n",
        "results = []\n",
        "\n",
        "for idx, (query, score) in enumerate(zip(queries, observations_scores)):\n",
        "    dims = len(query)\n",
        "    X_data = np.array([query])\n",
        "    y = -np.array([score])\n",
        "\n",
        "    # Train GP model\n",
        "    kernel = RBF()\n",
        "    gp = GaussianProcessRegressor(kernel=kernel)\n",
        "    gp.fit(X_data, y)\n",
        "\n",
        "    # Genetic Algorithm settings\n",
        "    POP_SIZE = 100\n",
        "    N_GEN = 30\n",
        "    N_ELITE = 10\n",
        "    MUTATION_RATE = 0.1\n",
        "\n",
        "    def random_candidate():\n",
        "        return np.random.uniform(0, 1, dims)\n",
        "\n",
        "    def mutate(vec):\n",
        "        return np.clip(vec + np.random.normal(0, 0.05, size=dims), 0, 1)\n",
        "\n",
        "    def crossover(p1, p2):\n",
        "        alpha = np.random.rand()\n",
        "        return np.clip(alpha * p1 + (1 - alpha) * p2, 0, 1)\n",
        "\n",
        "    def fitness(cand):\n",
        "        return -gp.predict(cand.reshape(1, -1))[0]\n",
        "\n",
        "    # Initialize population\n",
        "    population = np.array([random_candidate() for _ in range(POP_SIZE)])\n",
        "\n",
        "    # Run GA\n",
        "    for gen in range(N_GEN):\n",
        "        scores = np.array([fitness(ind) for ind in population])\n",
        "        elite_indices = scores.argsort()[:N_ELITE]\n",
        "        elite = population[elite_indices]\n",
        "\n",
        "        new_population = elite.tolist()\n",
        "        while len(new_population) < POP_SIZE:\n",
        "            parents = random.sample(list(elite), 2)\n",
        "            child = crossover(parents[0], parents[1])\n",
        "            if np.random.rand() < MUTATION_RATE:\n",
        "                child = mutate(child)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = np.array(new_population)\n",
        "\n",
        "    # Output best candidates for this function\n",
        "    final_scores = [fitness(ind) for ind in population]\n",
        "    top_indices = np.argsort(final_scores)[:5]\n",
        "    top_candidates = population[top_indices]\n",
        "\n",
        "    best_vectors = pd.DataFrame(top_candidates, columns=[f'x{i+1}' for i in range(dims)])\n",
        "    best_vectors['InputVec'] = best_vectors.apply(lambda row: '-'.join([f\"{row[f'x{i+1}']:.6f}\" for i in range(dims)]), axis=1)\n",
        "    best_vectors['Predicted_Score'] = [-fitness(ind) for ind in top_candidates]\n",
        "    best_vectors['Function'] = f'F{idx+1}'\n",
        "\n",
        "    results.append(best_vectors[['Function', 'InputVec', 'Predicted_Score']])\n",
        "\n",
        "# --- Step 3: Combine and show all results ---\n",
        "df_results = pd.concat(results, ignore_index=True)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GskptagHmC8L"
      },
      "outputs": [],
      "source": [
        "# --- Step 4: Prepare submission format (1 best vector per function) ---\n",
        "# Select the best (highest predicted score) per function\n",
        "submission_list = []\n",
        "\n",
        "for func in df_results['Function'].unique():\n",
        "    func_df = df_results[df_results['Function'] == func]\n",
        "    best_row = func_df.sort_values('Predicted_Score', ascending=False).iloc[0]\n",
        "    submission_list.append({\n",
        "        'Function': func,\n",
        "        'InputVec': best_row['InputVec']\n",
        "    })\n",
        "\n",
        "df_submission = pd.DataFrame(submission_list)\n",
        "\n",
        "# Export to CSV (Google Form-ready: Function - InputVec columns)\n",
        "submission_file = \"/content/Round10_Submission_Format.csv\"\n",
        "df_submission.to_csv(submission_file, index=False)\n",
        "\n",
        "# Show submission table\n",
        "df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qMXX1rsxmwDN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import random\n",
        "\n",
        "# Step 1: Define your queries and observed scores per function\n",
        "queries = [\n",
        "    [0.944034, 0.625117],  # F1\n",
        "    [0.768771, 0.105777],  # F2\n",
        "    [0.1456, 0.944454, 0.638992],  # F3\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562],  # F4\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022],  # F5\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],  # F6\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],  # F7\n",
        "    [0.25682, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776]  # F8\n",
        "]\n",
        "\n",
        "observations_scores = [\n",
        "    8.3316420728934,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.294127480893401,\n",
        "    8.294127480893401\n",
        "]\n",
        "\n",
        "# Step 2: Train GP + GA per function\n",
        "results = []\n",
        "\n",
        "for idx, (query, score) in enumerate(zip(queries, observations_scores)):\n",
        "    dims = len(query)\n",
        "    X_data = np.array([query])\n",
        "    y = -np.array([score])\n",
        "\n",
        "    kernel = RBF()\n",
        "    gp = GaussianProcessRegressor(kernel=kernel)\n",
        "    gp.fit(X_data, y)\n",
        "\n",
        "    POP_SIZE = 100\n",
        "    N_GEN = 30\n",
        "    N_ELITE = 10\n",
        "    MUTATION_RATE = 0.1\n",
        "\n",
        "    def random_candidate():\n",
        "        return np.random.uniform(0, 1, dims)\n",
        "\n",
        "    def mutate(vec):\n",
        "        return np.clip(vec + np.random.normal(0, 0.05, size=dims), 0, 1)\n",
        "\n",
        "    def crossover(p1, p2):\n",
        "        alpha = np.random.rand()\n",
        "        return np.clip(alpha * p1 + (1 - alpha) * p2, 0, 1)\n",
        "\n",
        "    def fitness(cand):\n",
        "        return -gp.predict(cand.reshape(1, -1))[0]\n",
        "\n",
        "    population = np.array([random_candidate() for _ in range(POP_SIZE)])\n",
        "\n",
        "    for gen in range(N_GEN):\n",
        "        scores = np.array([fitness(ind) for ind in population])\n",
        "        elite_indices = scores.argsort()[:N_ELITE]\n",
        "        elite = population[elite_indices]\n",
        "\n",
        "        new_population = elite.tolist()\n",
        "        while len(new_population) < POP_SIZE:\n",
        "            parents = random.sample(list(elite), 2)\n",
        "            child = crossover(parents[0], parents[1])\n",
        "            if np.random.rand() < MUTATION_RATE:\n",
        "                child = mutate(child)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = np.array(new_population)\n",
        "\n",
        "    final_scores = [fitness(ind) for ind in population]\n",
        "    top_indices = np.argsort(final_scores)[:5]\n",
        "    top_candidates = population[top_indices]\n",
        "\n",
        "    best_vectors = pd.DataFrame(top_candidates, columns=[f'x{i+1}' for i in range(dims)])\n",
        "    best_vectors['InputVec'] = best_vectors.apply(lambda row: '-'.join([f\"{row[f'x{i+1}']:.6f}\" for i in range(dims)]), axis=1)\n",
        "    best_vectors['Predicted_Score'] = [-fitness(ind) for ind in top_candidates]\n",
        "    best_vectors['Function'] = f'F{idx+1}'\n",
        "\n",
        "    results.append(best_vectors[['Function', 'InputVec', 'Predicted_Score']])\n",
        "\n",
        "df_results = pd.concat(results, ignore_index=True)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xdzInZk5nGtK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "import random\n",
        "\n",
        "# Example Step 1: Combine all known queries and observed scores (currently only Round 9, needs your past data added)\n",
        "queries = [\n",
        "    [0.944034, 0.625117],  # F1\n",
        "    [0.768771, 0.105777],  # F2\n",
        "    [0.1456, 0.944454, 0.638992],  # F3\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562],  # F4\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022],  # F5\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],  # F6\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],  # F7\n",
        "    [0.25682, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776]  # F8\n",
        "]\n",
        "\n",
        "observations_scores = [\n",
        "    8.3316420728934,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.434940976893401,\n",
        "    8.294127480893401,\n",
        "    8.294127480893401\n",
        "]\n",
        "\n",
        "# ⚠ Here you need to append your Round 1–8 queries and scores manually\n",
        "# Example:\n",
        "# queries.extend([...])\n",
        "# observations_scores.extend([...])\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, (query, score) in enumerate(zip(queries, observations_scores)):\n",
        "    dims = len(query)\n",
        "    X_data = np.array([query])\n",
        "    y = -np.array([score])\n",
        "\n",
        "    kernel = RBF()\n",
        "    gp = GaussianProcessRegressor(kernel=kernel)\n",
        "    gp.fit(X_data, y)\n",
        "\n",
        "    POP_SIZE = 100\n",
        "    N_GEN = 30\n",
        "    N_ELITE = 10\n",
        "    MUTATION_RATE = 0.1\n",
        "\n",
        "    def random_candidate():\n",
        "        return np.random.uniform(0, 1, dims)\n",
        "\n",
        "    def mutate(vec):\n",
        "        return np.clip(vec + np.random.normal(0, 0.05, size=dims), 0, 1)\n",
        "\n",
        "    def crossover(p1, p2):\n",
        "        alpha = np.random.rand()\n",
        "        return np.clip(alpha * p1 + (1 - alpha) * p2, 0, 1)\n",
        "\n",
        "    def fitness(cand):\n",
        "        return -gp.predict(cand.reshape(1, -1))[0]\n",
        "\n",
        "    population = np.array([random_candidate() for _ in range(POP_SIZE)])\n",
        "\n",
        "    for gen in range(N_GEN):\n",
        "        scores = np.array([fitness(ind) for ind in population])\n",
        "        elite_indices = scores.argsort()[:N_ELITE]\n",
        "        elite = population[elite_indices]\n",
        "\n",
        "        new_population = elite.tolist()\n",
        "        while len(new_population) < POP_SIZE:\n",
        "            parents = random.sample(list(elite), 2)\n",
        "            child = crossover(parents[0], parents[1])\n",
        "            if np.random.rand() < MUTATION_RATE:\n",
        "                child = mutate(child)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = np.array(new_population)\n",
        "\n",
        "    final_scores = [fitness(ind) for ind in population]\n",
        "    top_indices = np.argsort(final_scores)[:5]\n",
        "    top_candidates = population[top_indices]\n",
        "\n",
        "    best_vectors = pd.DataFrame(top_candidates, columns=[f'x{i+1}' for i in range(dims)])\n",
        "    best_vectors['InputVec'] = best_vectors.apply(lambda row: '-'.join([f\"{row[f'x{i+1}']:.6f}\" for i in range(dims)]), axis=1)\n",
        "    best_vectors['Predicted_Score'] = [-fitness(ind) for ind in top_candidates]\n",
        "    best_vectors['Function'] = f'F{idx+1}'\n",
        "\n",
        "    results.append(best_vectors[['Function', 'InputVec', 'Predicted_Score']])\n",
        "\n",
        "df_results = pd.concat(results, ignore_index=True)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95DpQr7NlQwQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6PW4EnUpoTLW"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/_ Function catalogue .csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TX4ykxIDohGx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load your existing catalogue\n",
        "df_catalogue = pd.read_csv(\"/content/_ Function catalogue .csv\")\n",
        "df_catalogue.columns = df_catalogue.columns.str.strip()\n",
        "\n",
        "# Step 2: Create your Round 9 submission and observations\n",
        "df_round9 = pd.DataFrame([\n",
        "    {\"Function\": \"F1\", \"Theme\": \"Searching for Contamination Sources\", \"InputVec\": \"0.944034-0.625117\", \"Score\": 8.3316420728934},\n",
        "    {\"Function\": \"F2\", \"Theme\": \"Optimising Noisy Models\", \"InputVec\": \"0.768771-0.105777\", \"Score\": 8.434940976893401},\n",
        "    {\"Function\": \"F3\", \"Theme\": \"Drug Discovery Problem\", \"InputVec\": \"0.1456-0.944454-0.638992\", \"Score\": 8.434940976893401},\n",
        "    {\"Function\": \"F4\", \"Theme\": \"Fast, but Inaccurate Modelling\", \"InputVec\": \"0.999363-0.440618-0.632742-0.573562\", \"Score\": 8.434940976893401},\n",
        "    {\"Function\": \"F5\", \"Theme\": \"Yield in a Chemical Reaction\", \"InputVec\": \"0.290636-0.824504-0.580542-0.368022\", \"Score\": 8.434940976893401},\n",
        "    {\"Function\": \"F6\", \"Theme\": \"Cake and Stuff\", \"InputVec\": \"0.404874-0.441523-0.135493-0.612513-0.497029\", \"Score\": 8.434940976893401},\n",
        "    {\"Function\": \"F7\", \"Theme\": \"Sometimes Lazy is Best\", \"InputVec\": \"0.304835-0.615316-0.890015-0.497555-0.892324-0.798193\", \"Score\": 8.294127480893401},\n",
        "    {\"Function\": \"F8\", \"Theme\": \"High-dimensional Optimisation\", \"InputVec\": \"0.25682-0.180489-0.295402-0.830171-0.672892-0.287181-0.913031-0.782776\", \"Score\": 8.294127480893401}\n",
        "])\n",
        "\n",
        "# Step 3: Append Round 9 to the existing catalogue\n",
        "df_updated = pd.concat([df_catalogue, df_round9], ignore_index=True)\n",
        "\n",
        "# Step 4: Save updated catalogue to a new file\n",
        "df_updated.to_csv(\"/content/Function_catalogue_updated.csv\", index=False)\n",
        "\n",
        "# Preview to confirm\n",
        "df_updated.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "awU0vRLuo2rw"
      },
      "outputs": [],
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=df_updated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_al4R0Uwq-BY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your cleaned catalogue\n",
        "df_check = pd.read_csv(\"/content/Function_catalogue_updated.csv\")\n",
        "df_check.columns = df_check.columns.str.strip()\n",
        "\n",
        "# Check number of rows per Function\n",
        "function_counts = df_check['Function'].value_counts().reset_index()\n",
        "function_counts.columns = ['Function', 'Number_of_Rows']\n",
        "\n",
        "function_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IXar1WwDrKLw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your current catalogue (Round 9 only)\n",
        "df_catalogue = pd.read_csv(\"/content/Function_catalogue_updated.csv\")\n",
        "df_catalogue.columns = df_catalogue.columns.str.strip()\n",
        "\n",
        "# Create a template for appending Round 1–8 data\n",
        "df_previous_rounds = pd.DataFrame([\n",
        "    {\"Function\": \"F1\", \"Theme\": \"Searching for Contamination Sources\", \"InputVec\": \"0.123456-0.654321\", \"Score\": 7.123},\n",
        "    {\"Function\": \"F1\", \"Theme\": \"Searching for Contamination Sources\", \"InputVec\": \"0.234567-0.543210\", \"Score\": 7.234},\n",
        "    {\"Function\": \"F2\", \"Theme\": \"Optimising Noisy Models\", \"InputVec\": \"0.345678-0.432109\", \"Score\": 7.345},\n",
        "    {\"Function\": \"F2\", \"Theme\": \"Optimising Noisy Models\", \"InputVec\": \"0.456789-0.321098\", \"Score\": 7.456},\n",
        "    {\"Function\": \"F3\", \"Theme\": \"Drug Discovery Problem\", \"InputVec\": \"0.567890-0.210987-0.109876\", \"Score\": 7.567},\n",
        "    # ⚠ Continue adding more data for all functions (F1 to F8) from your previous rounds...\n",
        "])\n",
        "\n",
        "# Append the new data\n",
        "df_combined = pd.concat([df_catalogue, df_previous_rounds], ignore_index=True)\n",
        "\n",
        "# Save the combined catalogue\n",
        "df_combined.to_csv(\"/content/Function_catalogue_all_rounds.csv\", index=False)\n",
        "\n",
        "df_combined.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HbnbUaOlroPD"
      },
      "outputs": [],
      "source": [
        "# Export the best candidate per function from df_results to a submission CSV\n",
        "\n",
        "# Select the best (highest predicted score) per function\n",
        "submission_list = []\n",
        "\n",
        "for func in df_results['Function'].unique():\n",
        "    func_df = df_results[df_results['Function'] == func]\n",
        "    best_row = func_df.sort_values('Predicted_Score', ascending=False).iloc[0]\n",
        "    submission_list.append({\n",
        "        'Function': func,\n",
        "        'InputVec': best_row['InputVec']\n",
        "    })\n",
        "\n",
        "df_submission = pd.DataFrame(submission_list)\n",
        "\n",
        "# Export to CSV\n",
        "submission_file = \"/content/Round10_Submission_Format.csv\"\n",
        "df_submission.to_csv(submission_file, index=False)\n",
        "\n",
        "# Display the submission DataFrame\n",
        "df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uvc-Pm7Xs0CI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you already have df_clean and parse_vec_general imported\n",
        "\n",
        "def inspect_clean(df):\n",
        "    \"\"\"\n",
        "    For each function, counts usable rows (non-null parsed vectors and scores)\n",
        "    and reports the unique dimensionalities found.\n",
        "    \"\"\"\n",
        "    inspection = []\n",
        "    # Re-parse the InputVec column in case you need to reconfirm its shape\n",
        "    df['ParsedVec'] = df['InputVec'].apply(parse_vec_general)\n",
        "\n",
        "    for func, group in df.groupby('Function'):\n",
        "        # Keep only rows with both a parsed vector and a valid Score\n",
        "        valid = group.dropna(subset=['ParsedVec', 'Score'])\n",
        "        # Compute dimensionality for each vector\n",
        "        dims = valid['ParsedVec'].apply(lambda v: v.shape[0] if hasattr(v, 'shape') else len(v))\n",
        "        inspection.append({\n",
        "            'Function': func,\n",
        "            'UsableRows': len(valid),\n",
        "            'Dimensionalities': sorted(dims.unique().tolist())\n",
        "        })\n",
        "\n",
        "    inspection_df = pd.DataFrame(inspection)\n",
        "    print(inspection_df)\n",
        "    return inspection_df\n",
        "\n",
        "# Run the inspection\n",
        "inspection_df = inspect_clean(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jb77NKNztA0t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def inspect_clean(df):\n",
        "    \"\"\"\n",
        "    For each function, counts usable rows (non-null parsed vectors and scores)\n",
        "    and reports the unique dimensionalities found.\n",
        "    \"\"\"\n",
        "    inspection = []\n",
        "    # Work on a copy so we don’t modify the original\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # Use map() so that each returned array/Series is kept as one object,\n",
        "    # rather than being expanded into multiple DataFrame columns.\n",
        "    df_clean['ParsedVec'] = df_clean['InputVec'].map(parse_vec_general)\n",
        "\n",
        "    for func, group in df_clean.groupby('Function'):\n",
        "        # Keep only rows where ParsedVec is present and Score is non-null\n",
        "        valid = group.dropna(subset=['ParsedVec', 'Score'])\n",
        "        # Compute dimensionality for each vector\n",
        "        dims = valid['ParsedVec'].apply(\n",
        "            lambda v: v.shape[0] if hasattr(v, 'shape') else len(v)\n",
        "        )\n",
        "        inspection.append({\n",
        "            'Function': func,\n",
        "            'UsableRows': len(valid),\n",
        "            'Dimensionalities': sorted(dims.unique().tolist())\n",
        "        })\n",
        "\n",
        "    inspection_df = pd.DataFrame(inspection)\n",
        "    print(inspection_df)\n",
        "    return inspection_df\n",
        "\n",
        "# Run the inspection\n",
        "inspection_df = inspect_clean(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BudoCcfmtKuR"
      },
      "outputs": [],
      "source": [
        "def inspect_bad_rows(df):\n",
        "    # Work on a copy\n",
        "    df_tmp = df.copy()\n",
        "    # Parse vectors, keeping failures as NaN\n",
        "    df_tmp['ParsedVec'] = df_tmp['InputVec'].map(parse_vec_general)\n",
        "    # Identify rows dropped in your training step\n",
        "    bad = df_tmp[df_tmp['ParsedVec'].isna() | df_tmp['Score'].isna()]\n",
        "\n",
        "    for func, group in bad.groupby('Function'):\n",
        "        print(f\"\\n=== Function {func}: {len(group)} bad rows ===\")\n",
        "        # Show the first few examples of what's malformed or missing\n",
        "        print(group[['InputVec', 'Score']].head().to_string(index=False))\n",
        "\n",
        "    # Also, compare against the original counts\n",
        "    print(\"\\nOriginal row counts per function:\")\n",
        "    print(df['Function'].value_counts().sort_index())\n",
        "\n",
        "# Run it\n",
        "inspect_bad_rows(df_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZK_6VVkptVX1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def inspect_bad_in_raw(df_raw):\n",
        "    \"\"\"\n",
        "    Parses every InputVec in the raw DataFrame, then\n",
        "    shows the rows where parsing failed or Score was missing.\n",
        "    \"\"\"\n",
        "    df = df_raw.copy()\n",
        "\n",
        "    # safe wrapper so a bad parse returns np.nan instead of exploding\n",
        "    def safe_parse(x):\n",
        "        try:\n",
        "            return parse_vec_general(x)\n",
        "        except Exception:\n",
        "            return np.nan\n",
        "\n",
        "    df['ParsedVec'] = df['InputVec'].map(safe_parse)\n",
        "\n",
        "    # these are the rows that will be dropped when you make df_clean\n",
        "    bad = df[df['ParsedVec'].isna() | df['Score'].isna()]\n",
        "\n",
        "    for func, grp in bad.groupby('Function'):\n",
        "        print(f\"\\n=== Function {func}: {len(grp)} dropped rows ===\")\n",
        "        print(grp[['InputVec','Score']].head().to_string(index=False))\n",
        "\n",
        "    print(\"\\nRaw row counts per function:\")\n",
        "    print(df_raw['Function'].value_counts().sort_index())\n",
        "\n",
        "# Usage: assuming your original data was loaded into df_raw\n",
        "inspect_bad_in_raw(df_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5cS0A715tbHQ"
      },
      "outputs": [],
      "source": [
        "# Right after loading your CSV / database / source...\n",
        "df_raw = df.copy()       # Keep an untouched copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N-Z1VfyKtdhW"
      },
      "outputs": [],
      "source": [
        "# e.g.:\n",
        "df_clean = (\n",
        "    df_raw\n",
        "    .assign(ParsedVec = lambda d: d['InputVec'].map(parse_vec_general))\n",
        "    .dropna(subset=['ParsedVec', 'Score'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n1PkAalGtmpO"
      },
      "outputs": [],
      "source": [
        "# If you haven’t yet, make df_raw as a copy of your original df\n",
        "# (do this immediately after loading your data)\n",
        "df_raw = df.copy()\n",
        "\n",
        "# Now inspect what columns exist\n",
        "print(\"Columns in df_raw:\", df_raw.columns.tolist())\n",
        "\n",
        "# And peek at the first few rows so we can see the actual names/structure\n",
        "print(df_raw.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZxPYH9Gvt-uV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zVS_rggztvgK"
      },
      "outputs": [],
      "source": [
        "# Skip the very first line, and use line 1 as your header:\n",
        "df_raw = pd.read_csv(\"mydata.csv\", header=1)\n",
        "\n",
        "# Now confirm you have the right columns:\n",
        "print(df_raw.columns.tolist())\n",
        "# → ['index', 'Function', 'Theme', 'InputVec', 'Score', ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4pjnqUdZt_x4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# List everything in /mnt/data (where your upload lives)\n",
        "print(os.listdir('/mnt/data'))\n",
        "\n",
        "# Or list the notebook’s working directory\n",
        "print(os.listdir('.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WyZZfeUYuDnl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def safe_parse(x):\n",
        "    try:\n",
        "        return parse_vec_general(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "df_raw['ParsedVec'] = df_raw['InputVec'].map(safe_parse)\n",
        "dropped = df_raw[df_raw['ParsedVec'].isna() | df_raw['Score'].isna()]\n",
        "\n",
        "for func, grp in dropped.groupby('Function'):\n",
        "    print(f\"\\n=== Function {func}: {len(grp)} dropped rows ===\")\n",
        "    print(grp[['InputVec','Score']].head().to_string(index=False))\n",
        "\n",
        "print(\"\\nRaw row counts per function:\")\n",
        "print(df_raw['Function'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TmyAhBfZuHo7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 1. List the current working directory\n",
        "print(\"CWD:\", os.getcwd())\n",
        "print(\"Files here:\", os.listdir('.'))\n",
        "\n",
        "# 2. Also check /content if you’re not in it\n",
        "print(\"/content:\", os.listdir('/content'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0IPGA4OFuQAE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the file with the bad header\n",
        "path = \"./_ Function catalogue .csv\"   # that “ ” is a narrow no-break space (\\u202f)\n",
        "\n",
        "# 1. Read it, using the second line as header\n",
        "df_raw = pd.read_csv(path, header=1)\n",
        "\n",
        "# 2. Keep only the columns you need\n",
        "df_raw = df_raw[['Function', 'Theme', 'InputVec', 'Score']]\n",
        "\n",
        "# 3. Verify\n",
        "print(\"Columns:\", df_raw.columns.tolist())\n",
        "print(df_raw.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KmUSR_4huZeK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Auto-detect the file whose name contains “Function catalogue”\n",
        "files = os.listdir('.')\n",
        "filename = next(f for f in files if 'Function catalogue' in f)\n",
        "print(\"Loading:\", filename)\n",
        "\n",
        "# 2. Read it, using the 2nd line as header\n",
        "df_raw = pd.read_csv(filename, header=1)\n",
        "\n",
        "# 3. Keep only the columns we care about\n",
        "df_raw = df_raw[['Function', 'Theme', 'InputVec', 'Score']]\n",
        "\n",
        "# 4. Verify\n",
        "print(\"Columns:\", df_raw.columns.tolist())\n",
        "print(df_raw.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fzbYFPDbudTY"
      },
      "outputs": [],
      "source": [
        "def safe_parse(x):\n",
        "    try:\n",
        "        return parse_vec_general(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "# 5. Parse every InputVec safely\n",
        "df_raw['ParsedVec'] = df_raw['InputVec'].map(safe_parse)\n",
        "\n",
        "# 6. Find what would be dropped\n",
        "dropped = df_raw[df_raw['ParsedVec'].isna() | df_raw['Score'].isna()]\n",
        "\n",
        "# 7. Report by function\n",
        "for func, grp in dropped.groupby('Function'):\n",
        "    print(f\"\\n=== Function {func}: {len(grp)} dropped rows ===\")\n",
        "    print(grp[['InputVec','Score']].head().to_string(index=False))\n",
        "\n",
        "# 8. Show raw totals\n",
        "print(\"\\nRaw row counts per function:\")\n",
        "print(df_raw['Function'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_Dxzt3RWurB1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Wrap parse_vec_general so failures become NaN\n",
        "def safe_parse(x):\n",
        "    try:\n",
        "        return parse_vec_general(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "# 2) Apply to every row\n",
        "df_raw['ParsedVec'] = df_raw['InputVec'].map(safe_parse)\n",
        "\n",
        "# 3) Select the “bad” ones\n",
        "dropped = df_raw[df_raw['ParsedVec'].isna() | df_raw['Score'].isna()]\n",
        "\n",
        "# 4) Print a summary by function\n",
        "for func, grp in dropped.groupby('Function'):\n",
        "    print(f\"\\n=== Function {func}: {len(grp)} dropped rows ===\")\n",
        "    print(grp[['InputVec','Score']].head().to_string(index=False))\n",
        "\n",
        "# 5) And show your raw totals again for reference\n",
        "print(\"\\nRaw row counts per function:\")\n",
        "print(df_raw['Function'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CGaZUahAuyGn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Safe-parse as before\n",
        "def safe_parse(x):\n",
        "    try:\n",
        "        return parse_vec_general(x)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "df_raw['ParsedVec'] = df_raw['InputVec'].map(safe_parse)\n",
        "\n",
        "# 2) Identify all dropped rows\n",
        "dropped = df_raw[df_raw['ParsedVec'].isna() | df_raw['Score'].isna()]\n",
        "\n",
        "# 3) Print total count\n",
        "print(\"Total rows dropped:\", len(dropped))\n",
        "\n",
        "# 4) If there are any, show the first 10 examples\n",
        "if len(dropped) > 0:\n",
        "    print(\"\\nSample dropped rows:\")\n",
        "    print(dropped[['Function','InputVec','Score']].head(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nNo rows failed parsing or had missing scores.\")\n",
        "\n",
        "# 5) And per-function drop counts\n",
        "print(\"\\nDropped rows per function:\")\n",
        "print(dropped['Function'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TFZ6T5hdvA4a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Choose your expected dimension\n",
        "expected_dim = 8\n",
        "\n",
        "# 2. Parse every InputVec (no safe‐wrap so we see real shapes or errors)\n",
        "df_raw['ParsedVec'] = df_raw['InputVec'].map(parse_vec_general)\n",
        "\n",
        "# 3. Compute each vector’s length\n",
        "df_raw['Dim'] = df_raw['ParsedVec'].apply(\n",
        "    lambda v: v.shape[0] if hasattr(v, 'shape')\n",
        "              else (len(v) if v is not None else np.nan)\n",
        ")\n",
        "\n",
        "# 4. Show the dimensionality distribution\n",
        "print(\"Dimensionality distribution:\")\n",
        "print(df_raw['Dim'].value_counts().sort_index())\n",
        "\n",
        "# 5. Find rows with the “wrong” dim or missing Score\n",
        "bad = df_raw[(df_raw['Dim'] != expected_dim) | df_raw['Score'].isna()]\n",
        "\n",
        "# 6. Summary\n",
        "print(f\"\\nTotal bad rows (dim≠{expected_dim} or no Score):\", len(bad))\n",
        "if len(bad):\n",
        "    print(\"\\nSample bad rows:\")\n",
        "    print(bad[['Function','InputVec','Dim','Score']].head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nBad rows per function:\")\n",
        "print(bad['Function'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6oAyMOOmvRFy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1) Make sure Score is numeric\n",
        "df_raw['Score'] = pd.to_numeric(df_raw['Score'], errors='coerce')\n",
        "\n",
        "# 2) (Re-)parse every InputVec\n",
        "df_raw['ParsedVec'] = df_raw['InputVec'].map(lambda x:\n",
        "    parse_vec_general(x)\n",
        ")\n",
        "\n",
        "# 3) Drop only rows missing a parsed vector or score\n",
        "df_clean = df_raw.dropna(subset=['ParsedVec','Score']).copy()\n",
        "\n",
        "# 4) Summarize usable rows and dims per function\n",
        "inspection = []\n",
        "for func, grp in df_clean.groupby('Function'):\n",
        "    # lengths of each vector\n",
        "    dims = [v.shape[0] for v in grp['ParsedVec']]\n",
        "    inspection.append({\n",
        "        'Function': func,\n",
        "        'UsableRows': len(grp),\n",
        "        'Dimensionalities': sorted(set(dims))\n",
        "    })\n",
        "\n",
        "inspection_df = pd.DataFrame(inspection)\n",
        "print(inspection_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KQenr91Wvbh4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def build_clean_df(df_raw):\n",
        "    # 1) Ensure Score is numeric\n",
        "    df_raw['Score'] = pd.to_numeric(df_raw['Score'], errors='coerce')\n",
        "\n",
        "    # 2) Parse vectors\n",
        "    df_raw['ParsedVec'] = df_raw['InputVec'].map(parse_vec_general)\n",
        "\n",
        "    # 3) Drop any bad rows\n",
        "    df_clean = df_raw.dropna(subset=['ParsedVec','Score']).copy()\n",
        "    return df_clean\n",
        "\n",
        "def validate_functions(df_clean, min_samples=5, expected_dim=8):\n",
        "    stats = df_clean.groupby('Function')['ParsedVec'] \\\n",
        "            .agg(count=lambda xs: len(xs),\n",
        "                 dims=lambda xs: sorted({len(v) for v in xs}))\n",
        "    for func, row in stats.iterrows():\n",
        "        cnt, dims = row['count'], row['dims']\n",
        "        if cnt < min_samples:\n",
        "            raise ValueError(f\"Function {func!r} has only {cnt} samples (<{min_samples})\")\n",
        "        if dims != [expected_dim]:\n",
        "            raise ValueError(f\"Function {func!r} has unexpected vector dims: {dims}\")\n",
        "    return stats\n",
        "\n",
        "def assemble_xy(df_clean):\n",
        "    X = np.stack(df_clean['ParsedVec'].values)   # shape: (N, 8)\n",
        "    y = df_clean['Score'].values                 # shape: (N,)\n",
        "    return X, y\n",
        "\n",
        "# --- USAGE ---\n",
        "# 1) Build df_clean\n",
        "df_clean = build_clean_df(df_raw)\n",
        "\n",
        "# 2) Validate\n",
        "stats = validate_functions(df_clean)\n",
        "print(\"All functions OK:\\n\", stats)\n",
        "\n",
        "# 3) Assemble data\n",
        "X, y = assemble_xy(df_clean)\n",
        "\n",
        "# 4) Train your GP+GA model\n",
        "#    (replace the next lines with your actual training call)\n",
        "model = YourGPGAClass(...)\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ycM-tAPhvgoe"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "\n",
        "# 1. Define a kernel (constant × RBF) and GP regressor\n",
        "kernel = C(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
        "model = GaussianProcessRegressor(\n",
        "    kernel=kernel,\n",
        "    n_restarts_optimizer=5,\n",
        "    normalize_y=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Fit to your data\n",
        "model.fit(X, y)\n",
        "\n",
        "# 3. Quick check\n",
        "print(\"Optimized kernel:\", model.kernel_)\n",
        "print(\"Log-marginal-likelihood:\", model.log_marginal_likelihood(model.kernel_.theta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KbQ7nbKQvnDU"
      },
      "outputs": [],
      "source": [
        "from your_module import GPGA   # wherever you defined it\n",
        "\n",
        "# 1. Instantiate with whatever hyperparameters make sense\n",
        "model = GPGA(pop_size=100, generations=30, crossover_rate=0.8, mutation_rate=0.1)\n",
        "\n",
        "# 2. Train on your data\n",
        "model.fit(X, y)\n",
        "\n",
        "# 3. (Optional) Inspect fitness history or best individual\n",
        "print(\"Best fitness per generation:\", model.best_fitness_per_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "anHsAj2nvzY-"
      },
      "outputs": [],
      "source": [
        "print(\"Optimized kernel:\", model.kernel_)\n",
        "print(\"Log-marginal-likelihood:\", model.log_marginal_likelihood(model.kernel_.theta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eyF32v9tv_DE"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from your_module import GPGA   # your custom class\n",
        "\n",
        "# 1) Split once for a quick train/test on the GP\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2) Build and fit the GaussianProcessRegressor\n",
        "kernel = C(1.0, (1e-3, 1e3)) * RBF(\n",
        "    length_scale=1.0, length_scale_bounds=(1e-2, 1e2)\n",
        ")\n",
        "gp_model = GaussianProcessRegressor(\n",
        "    kernel=kernel,\n",
        "    n_restarts_optimizer=5,\n",
        "    normalize_y=True,\n",
        "    random_state=42\n",
        ")\n",
        "gp_model.fit(X_train, y_train)\n",
        "\n",
        "# 3) Inspect the fitted GP\n",
        "print(\"Optimized kernel:\", gp_model.kernel_)\n",
        "print(\"Log-marginal-likelihood:\",\n",
        "      gp_model.log_marginal_likelihood())  # no need to pass theta\n",
        "\n",
        "# 4) Evaluate on held-out data\n",
        "y_pred, y_std = gp_model.predict(X_test, return_std=True)\n",
        "print(\"Test R²:\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ne5ncVBrwJU_"
      },
      "outputs": [],
      "source": [
        "# --- cell 1: your GPGA class definition ---\n",
        "import numpy as np\n",
        "\n",
        "class GPGA:\n",
        "    def __init__(self, pop_size=50, generations=20,\n",
        "                 crossover_rate=0.8, mutation_rate=0.1,\n",
        "                 random_state=None):\n",
        "        self.pop_size = pop_size\n",
        "        self.generations = generations\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.random_state = random_state\n",
        "        self.best_fitness_per_gen = []\n",
        "        self.best_individual_ = None\n",
        "        self.best_fitness_ = None\n",
        "        # … any other setup …\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "        # initialize population of hyperparameter sets (or kernel params)\n",
        "        population = self._init_population(rng)\n",
        "        for gen in range(self.generations):\n",
        "            # 1) evaluate fitness of each individual\n",
        "            fitness = [self._evaluate(ind, X, y) for ind in population]\n",
        "            # 2) record the best\n",
        "            best_idx = np.argmax(fitness)\n",
        "            self.best_fitness_per_gen.append(fitness[best_idx])\n",
        "            self.best_individual_ = population[best_idx]\n",
        "            self.best_fitness_ = fitness[best_idx]\n",
        "            # 3) select, crossover, mutate to form next gen\n",
        "            population = self._next_generation(population, fitness, rng)\n",
        "        return self\n",
        "\n",
        "    # stub methods—fill these in with your GA logic:\n",
        "    def _init_population(self, rng): ...\n",
        "    def _evaluate(self, individual, X, y): ...\n",
        "    def _next_generation(self, population, fitness, rng): ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vxG-vZxBwM9F"
      },
      "outputs": [],
      "source": [
        "# --- cell 2: import and use it ---\n",
        "# (No import needed if it’s in the same notebook — just call it directly)\n",
        "ga_model = GPGA(pop_size=100, generations=30, random_state=42)\n",
        "ga_model.fit(X, y)\n",
        "print(\"GA best fitness per generation:\", ga_model.best_fitness_per_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VE1ZA5RVwgOs"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
        "\n",
        "class GPGA:\n",
        "    def __init__(self, pop_size=50, generations=20,\n",
        "                 crossover_rate=0.8, mutation_rate=0.1,\n",
        "                 amp_bounds=(1e-3, 1e3), ls_bounds=(1e-2, 1e2),\n",
        "                 random_state=None):\n",
        "        self.pop_size = pop_size\n",
        "        self.generations = generations\n",
        "        self.crossover_rate = crossover_rate\n",
        "        self.mutation_rate = mutation_rate\n",
        "        self.amp_bounds = amp_bounds\n",
        "        self.ls_bounds = ls_bounds\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # history\n",
        "        self.best_fitness_per_gen = []\n",
        "        self.best_individual_ = None\n",
        "        self.best_fitness_ = None\n",
        "\n",
        "    def _init_population(self, rng):\n",
        "        # Each individual is [amplitude, length_scale]\n",
        "        low = np.array([self.amp_bounds[0], self.ls_bounds[0]])\n",
        "        high= np.array([self.amp_bounds[1], self.ls_bounds[1]])\n",
        "        return [rng.uniform(low, high) for _ in range(self.pop_size)]\n",
        "\n",
        "    def _evaluate(self, individual, X, y):\n",
        "        amp, ls = individual\n",
        "        kernel = C(amp, self.amp_bounds) * RBF(length_scale=ls,\n",
        "                                               length_scale_bounds=self.ls_bounds)\n",
        "        gp = GaussianProcessRegressor(kernel=kernel,\n",
        "                                      normalize_y=True,\n",
        "                                      random_state=self.random_state)\n",
        "        gp.fit(X, y)\n",
        "        # we’ll use log-marginal-likelihood as fitness\n",
        "        return gp.log_marginal_likelihood()\n",
        "\n",
        "    def _next_generation(self, population, fitness, rng):\n",
        "        # Simple tournament selection + arithmetic crossover + Gaussian mutation\n",
        "\n",
        "        # 1) Tournament: pick 2 at random, take the better\n",
        "        def select_one():\n",
        "            i, j = rng.choice(len(population), size=2, replace=False)\n",
        "            return population[i] if fitness[i] > fitness[j] else population[j]\n",
        "\n",
        "        # 2) Build next pop\n",
        "        new_pop = []\n",
        "        while len(new_pop) < self.pop_size:\n",
        "            # select parents\n",
        "            p1, p2 = select_one(), select_one()\n",
        "            # crossover\n",
        "            if rng.rand() < self.crossover_rate:\n",
        "                alpha = rng.rand()\n",
        "                child = alpha*p1 + (1-alpha)*p2\n",
        "            else:\n",
        "                child = p1.copy()\n",
        "            # mutation\n",
        "            if rng.rand() < self.mutation_rate:\n",
        "                child += rng.normal(scale=0.1, size=child.shape)\n",
        "                # clip back into bounds\n",
        "                child = np.clip(child,\n",
        "                                [self.amp_bounds[0], self.ls_bounds[0]],\n",
        "                                [self.amp_bounds[1], self.ls_bounds[1]])\n",
        "            new_pop.append(child)\n",
        "        return new_pop\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "        population = self._init_population(rng)\n",
        "        for gen in range(self.generations):\n",
        "            fitness = [self._evaluate(ind, X, y) for ind in population]\n",
        "            best_idx = int(np.argmax(fitness))\n",
        "            self.best_fitness_per_gen.append(fitness[best_idx])\n",
        "            self.best_individual_ = population[best_idx].copy()\n",
        "            self.best_fitness_ = fitness[best_idx]\n",
        "            population = self._next_generation(population, fitness, rng)\n",
        "        return self"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "If1wx_lPwiQX"
      },
      "outputs": [],
      "source": [
        "# Instantiate & run\n",
        "ga_model = GPGA(\n",
        "    pop_size=100,\n",
        "    generations=30,\n",
        "    crossover_rate=0.8,\n",
        "    mutation_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "ga_model.fit(X, y)\n",
        "\n",
        "print(\"GA best fitness per generation:\", ga_model.best_fitness_per_gen)\n",
        "print(\"GA overall best individual:\", ga_model.best_individual_)\n",
        "print(\"GA best fitness:\", ga_model.best_fitness_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9qFAwfzXwtbP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# How many total NaNs?\n",
        "total_nans = np.isnan(X).sum()\n",
        "print(\"Total NaN entries in X:\", total_nans)\n",
        "\n",
        "# Does any row contain a NaN?\n",
        "rows_with_nans = np.where(np.isnan(X).any(axis=1))[0]\n",
        "print(\"Rows with NaNs:\", rows_with_nans)\n",
        "\n",
        "# And for sanity, check scores too:\n",
        "print(\"Any NaNs in y?\", np.isnan(y).any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YbfPrCzZw5AX"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 1) Inspect how many NaNs in each dimension\n",
        "import numpy as np\n",
        "nans_per_dim = np.isnan(X).sum(axis=0)\n",
        "print(\"NaNs per feature (dim):\", nans_per_dim)\n",
        "\n",
        "# 2) Impute (fill) each column with its mean\n",
        "imp = SimpleImputer(strategy='mean')\n",
        "X_imputed = imp.fit_transform(X)\n",
        "\n",
        "# 3) Double-check no more NaNs\n",
        "print(\"Any NaNs left in X_imputed?\", np.isnan(X_imputed).any())\n",
        "\n",
        "# 4) Retrain your GA-wrapped GP on the imputed data\n",
        "ga_model = GPGA(\n",
        "    pop_size=100,\n",
        "    generations=30,\n",
        "    crossover_rate=0.8,\n",
        "    mutation_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "ga_model.fit(X_imputed, y)\n",
        "\n",
        "print(\"GA best fitness per generation:\", ga_model.best_fitness_per_gen)\n",
        "print(\"GA best individual (amp, ls):\", ga_model.best_individual_)\n",
        "print(\"GA best fitness:\", ga_model.best_fitness_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oi6onCjlxCoR"
      },
      "outputs": [],
      "source": [
        "# Check shapes immediately before fitting\n",
        "print(\"X_imputed.shape:\", X_imputed.shape)\n",
        "print(\"y.shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PzuHz8xYxNkO"
      },
      "outputs": [],
      "source": [
        "# Rebuild y from df_clean\n",
        "y = df_clean['Score'].values\n",
        "\n",
        "# Verify shapes\n",
        "print(\"X_imputed.shape:\", X_imputed.shape)   # should be (175, 8)\n",
        "print(\"y.shape:\", y.shape)                   # should now be (175,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hzlu1MvbxPxc"
      },
      "outputs": [],
      "source": [
        "ga_model.fit(X_imputed, y)\n",
        "print(\"GA best fitness per generation:\", ga_model.best_fitness_per_gen)\n",
        "print(\"GA best individual:\", ga_model.best_individual_)\n",
        "print(\"GA best fitness:\", ga_model.best_fitness_) import time\n",
        "\n",
        "# grab one population and RNG from your model\n",
        "rng = np.random.RandomState(42)\n",
        "pop = ga_model._init_population(rng)\n",
        "\n",
        "# time how long it takes to eval that one generation\n",
        "start = time.time()\n",
        "_ = [ga_model._evaluate(ind, X_imputed, y) for ind in pop]\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(f\"1 generation ({len(pop)} fits) took {elapsed:.1f}s\")\n",
        "print(f\"Estimated total time: {elapsed * ga_model.generations:.1f}s (~{(elapsed * ga_model.generations)/60:.1f}min)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X24NdlJW6hBm"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, RBF\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1) Split (if you haven’t already)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2) Build a GP with the GA’s best hyper-parameters and no optimizer\n",
        "amp, ls = ga_model.best_individual_\n",
        "kernel = C(amp, (amp, amp)) * RBF(length_scale=ls, length_scale_bounds=(ls, ls))\n",
        "gp = GaussianProcessRegressor(\n",
        "    kernel=kernel,\n",
        "    normalize_y=True,\n",
        "    optimizer=None  # ← turn off SciPy optimization entirely\n",
        ")\n",
        "\n",
        "# 3) Fit & evaluate\n",
        "gp.fit(X_train, y_train)\n",
        "y_pred, y_std = gp.predict(X_test, return_std=True)\n",
        "\n",
        "print(\"Test R²:\",   r2_score(y_test, y_pred))\n",
        "print(\"Test LL:\",   gp.log_marginal_likelihood())  # now works without the status error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2qvzCoIO6xAI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "class GPGA_CV(GPGA):\n",
        "    def _evaluate(self, individual, X, y):\n",
        "        amp, ls = individual\n",
        "        kernel = C(amp, self.amp_bounds) * RBF(\n",
        "            length_scale=ls, length_scale_bounds=self.ls_bounds\n",
        "        )\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
        "        scores = []\n",
        "        for tr, te in kf.split(X):\n",
        "            gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True,\n",
        "                                          optimizer=None)\n",
        "            gp.fit(X[tr], y[tr])\n",
        "            y_pred = gp.predict(X[te])\n",
        "            scores.append(r2_score(y[te], y_pred))\n",
        "        return np.mean(scores)  # higher = better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2OhRDDjT60lm"
      },
      "outputs": [],
      "source": [
        " class GPGA:\n",
        "-    def __init__(…, ls_bounds=(1e-2, 1e2), …):\n",
        "+    def __init__(…, ls_bounds=(1e-2, 10), …):\n",
        "         …"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B5BmpN0R64Yk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1) Fit scalers on training folds inside GPGA_CV._evaluate\n",
        "x_scaler = StandardScaler().fit(X[tr])\n",
        "y_scaler = StandardScaler().fit(y[tr].reshape(-1,1))\n",
        "\n",
        "X_tr_s = x_scaler.transform(X[tr])\n",
        "X_te_s = x_scaler.transform(X[te])\n",
        "y_tr_s = y_scaler.transform(y[tr].reshape(-1,1)).ravel()\n",
        "\n",
        "gp.fit(X_tr_s, y_tr_s)\n",
        "y_pred_s = gp.predict(X_te_s)\n",
        "y_pred = y_scaler.inverse_transform(y_pred_s.reshape(-1,1)).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1xUu7fzA67ku"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "xs = StandardScaler().fit_transform(X_imputed)\n",
        "ys = StandardScaler().fit_transform(y.reshape(-1,1)).ravel()\n",
        "# Then run ga_model.fit(xs, ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YzG7mZFD7GbR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, RBF\n",
        "\n",
        "# 1) Split BEFORE scaling to preserve a true hold-out set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2) Fit scalers on train only\n",
        "x_sc = StandardScaler().fit(X_train)\n",
        "y_sc = StandardScaler().fit(y_train.reshape(-1,1))\n",
        "\n",
        "X_tr_s = x_sc.transform(X_train)\n",
        "X_te_s = x_sc.transform(X_test)\n",
        "y_tr_s = y_sc.transform(y_train.reshape(-1,1)).ravel()\n",
        "\n",
        "# 3) Rerun GA on scaled training data\n",
        "ga_model = GPGA(\n",
        "    pop_size=50,       # you can reduce for speed\n",
        "    generations=15,    # fewer gens now that scaling helps\n",
        "    crossover_rate=0.8,\n",
        "    mutation_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "ga_model.fit(X_tr_s, y_tr_s)\n",
        "\n",
        "print(\"GA best fitness per generation:\", ga_model.best_fitness_per_gen)\n",
        "print(\"GA best hyperparams [amp, ls]:\", ga_model.best_individual_)\n",
        "\n",
        "# 4) Build a GP with those hyper-parameters and no optimizer\n",
        "amp, ls = ga_model.best_individual_\n",
        "kernel = C(amp, (amp, amp)) * RBF(length_scale=ls, length_scale_bounds=(ls, ls))\n",
        "gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True, optimizer=None)\n",
        "\n",
        "# 5) Fit GP on the scaled train set\n",
        "gp.fit(X_tr_s, y_tr_s)\n",
        "\n",
        "# 6) Predict on the scaled test set, then invert the scaling on y_pred\n",
        "y_pred_s, y_std_s = gp.predict(X_te_s, return_std=True)\n",
        "y_pred = y_sc.inverse_transform(y_pred_s.reshape(-1,1)).ravel()\n",
        "\n",
        "# 7) Evaluate on unscaled test targets\n",
        "print(\"Test  R² (unscaled):\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hQK55uvy8AKV"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, RBF\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "class GPGA_CV(GPGA):\n",
        "    def __init__(self, *args, n_splits=5, optimizer=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.n_splits = n_splits\n",
        "        self.optimizer = optimizer  # pass through to GP\n",
        "\n",
        "    def _evaluate(self, individual, X, y):\n",
        "        # Build a fixed-kernel GP\n",
        "        amp, ls = individual\n",
        "        kernel = C(amp, self.amp_bounds) * RBF(\n",
        "            length_scale=ls, length_scale_bounds=self.ls_bounds\n",
        "        )\n",
        "\n",
        "        cv = KFold(n_splits=self.n_splits,\n",
        "                   shuffle=True, random_state=self.random_state)\n",
        "        scores = []\n",
        "        for train_idx, test_idx in cv.split(X):\n",
        "            X_tr, X_te = X[train_idx], X[test_idx]\n",
        "            y_tr, y_te = y[train_idx], y[test_idx]\n",
        "\n",
        "            gp = GaussianProcessRegressor(\n",
        "                kernel=kernel,\n",
        "                normalize_y=True,\n",
        "                optimizer=self.optimizer,  # skip internal SciPy if None\n",
        "                random_state=self.random_state\n",
        "            )\n",
        "            gp.fit(X_tr, y_tr)\n",
        "            y_pred = gp.predict(X_te)\n",
        "            scores.append(r2_score(y_te, y_pred))\n",
        "        return np.mean(scores)  # higher R² is better\n",
        "\n",
        "# --- USAGE on your scaled data ---\n",
        "ga_cv = GPGA_CV(\n",
        "    pop_size=50,       # smaller for speed\n",
        "    generations=15,\n",
        "    crossover_rate=0.8,\n",
        "    mutation_rate=0.1,\n",
        "    amp_bounds=(1e-3,1e3),\n",
        "    ls_bounds=(1e-2,10),   # tightened upper bound\n",
        "    random_state=42,\n",
        "    optimizer=None,       # prevents SciPy errors\n",
        "    n_splits=5\n",
        ")\n",
        "\n",
        "# Fit on scaled train set\n",
        "ga_cv.fit(xs, ys)\n",
        "\n",
        "print(\"GA_CV best fitness per generation:\", ga_cv.best_fitness_per_gen)\n",
        "print(\"GA_CV best hyperparams [amp, ls]:\", ga_cv.best_individual_)\n",
        "print(\"GA_CV best CV R²:\", ga_cv.best_fitness_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oB8FZYHz_7W6"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, Matern, WhiteKernel\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "\n",
        "# Pull in your best GA‐CV hyperparams:\n",
        "amp, ls = ga_cv.best_individual_\n",
        "\n",
        "# Define a Matern + white‐noise kernel\n",
        "kernel = (\n",
        "    C(amp, (1e-3, 1e3))\n",
        "    * Matern(length_scale=ls, length_scale_bounds=(1e-4, 5), nu=1.5)\n",
        "    + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-5, 1e1))\n",
        ")\n",
        "\n",
        "# Build a GP that *doesn't* re-optimize (optimizer=None)\n",
        "gp = GaussianProcessRegressor(\n",
        "    kernel=kernel,\n",
        "    normalize_y=True,\n",
        "    optimizer=None,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit on your scaled train data:\n",
        "gp.fit(X_tr_s, y_tr_s)\n",
        "\n",
        "# Predict on the scaled test set and invert the scaling:\n",
        "y_pred_s, y_std_s = gp.predict(X_te_s, return_std=True)\n",
        "y_pred = y_sc.inverse_transform(y_pred_s.reshape(-1,1)).ravel()\n",
        "\n",
        "# Evaluate:\n",
        "from sklearn.metrics import r2_score\n",
        "print(\"Test R² (Matern+White):\", r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WFWN-sexAIUq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1) Split on the imputed unscaled data\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X_imputed, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2) Instantiate and fit\n",
        "hgb = HistGradientBoostingRegressor(\n",
        "    max_iter=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "hgb.fit(X_tr, y_tr)\n",
        "\n",
        "# 3) Evaluate on test set\n",
        "y_pred = hgb.predict(X_te)\n",
        "print(\"HGB Test R²:\", r2_score(y_te, y_pred))\n",
        "\n",
        "# 4) (Optional) 5-fold CV on full dataset\n",
        "cv_scores = cross_val_score(\n",
        "    hgb, X_imputed, y, cv=5, scoring=\"r2\", n_jobs=-1\n",
        ")\n",
        "print(\"HGB CV  R² mean:\", cv_scores.mean(), \"±\", cv_scores.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0V2ijzd7ANSy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_te, y_pred, alpha=0.6)\n",
        "lims = [min(y_te.min(), y_pred.min()), max(y_te.max(), y_pred.max())]\n",
        "plt.plot(lims, lims, 'k--')\n",
        "plt.xlabel(\"True Score\"); plt.ylabel(\"Predicted Score\")\n",
        "plt.title(\"HGB: True vs Predicted\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dTxATluNAg7-"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "results = []\n",
        "for func, group in df_clean.groupby('Function'):\n",
        "    # 1) Extract that function’s true input vectors & scores\n",
        "    Xf = np.stack(group['ParsedVec'].values)   # shape: (n_samples, dim_f)\n",
        "    yf = group['Score'].values                 # shape: (n_samples,)\n",
        "\n",
        "    # 2) Fit & CV-test a simple model\n",
        "    model = HistGradientBoostingRegressor(\n",
        "        max_iter=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    # 5-fold CV R²\n",
        "    scores = cross_val_score(model, Xf, yf, cv=5, scoring=\"r2\", n_jobs=-1)\n",
        "    results.append((func, scores.mean(), scores.std()))\n",
        "\n",
        "# 3) Tabulate\n",
        "import pandas as pd\n",
        "df_func_perf = pd.DataFrame(results, columns=[\"Function\",\"R2_mean\",\"R2_std\"])\n",
        "print(df_func_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EVVQm0kcAkyG"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "Xf2 = poly.fit_transform(Xf)\n",
        "# then cross_val_score on Xf2 instead of Xf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-hWdHKcxAmpX"
      },
      "outputs": [],
      "source": [
        "# e.g. for F4 only:\n",
        "f4 = df_clean[df_clean['Function']==\"F4\"]\n",
        "Xf4 = np.stack(f4['ParsedVec'].values)\n",
        "yf4 = f4['Score'].values\n",
        "\n",
        "# scale, then GA_CV.fit(Xf4_s, yf4_s) as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OjE85ZBoBA-3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "results_poly = []\n",
        "\n",
        "for func, group in df_clean.groupby(\"Function\"):\n",
        "    # 1) Build a boolean mask of that function’s rows\n",
        "    mask = df_clean[\"Function\"] == func\n",
        "\n",
        "    # 2) Pull the imputed vectors & scores\n",
        "    Xf = X_imputed[mask]       # shape: (n_func, 8), no NaNs\n",
        "    yf = group[\"Score\"].values # shape: (n_func,)\n",
        "\n",
        "    # 3) Make 2nd-degree features\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    Xf2 = poly.fit_transform(Xf)\n",
        "\n",
        "    # 4) 5-fold CV\n",
        "    hgb = HistGradientBoostingRegressor(\n",
        "        max_iter=200, learning_rate=0.1, max_depth=5, random_state=42\n",
        "    )\n",
        "    scores = cross_val_score(\n",
        "        hgb, Xf2, yf, cv=5, scoring=\"r2\", n_jobs=-1\n",
        "    )\n",
        "\n",
        "    results_poly.append({\n",
        "        \"Function\": func,\n",
        "        \"R2_mean_poly\": scores.mean(),\n",
        "        \"R2_std_poly\": scores.std()\n",
        "    })\n",
        "\n",
        "df_poly_perf = pd.DataFrame(results_poly)\n",
        "print(df_poly_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nLe20sOmBOQW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "results_ttr = []\n",
        "\n",
        "for func, group in df_clean.groupby(\"Function\"):\n",
        "    # 1) Raw inputs & scores\n",
        "    Xf = X_imputed[df_clean[\"Function\"]==func]  # no NaNs\n",
        "    yf = group[\"Score\"].values                  # may be wildly skewed\n",
        "\n",
        "    # 2) Build pipeline: X scaled, y Yeo–Johnson\n",
        "    x_sc = StandardScaler()\n",
        "    pt  = PowerTransformer(method=\"yeo-johnson\", standardize=True)\n",
        "    base = HistGradientBoostingRegressor(\n",
        "        max_iter=200, learning_rate=0.1, max_depth=5, random_state=42\n",
        "    )\n",
        "    model = TransformedTargetRegressor(\n",
        "        regressor=base,\n",
        "        transformer=pt,\n",
        "        func=None,           # not needed if transformer handles inverse\n",
        "    )\n",
        "    # Wrap in an X-scaler via a simple pipeline\n",
        "    # but cross_val_score can’t handle two-step pipelines and TTR\n",
        "    # so we’ll manually scale X and use TTR directly:\n",
        "\n",
        "    Xf_s = x_sc.fit_transform(Xf)\n",
        "\n",
        "    # 3) 5-fold CV on the transformed target\n",
        "    scores = cross_val_score(\n",
        "        model, Xf_s, yf,\n",
        "        cv=5,\n",
        "        scoring=\"r2\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    results_ttr.append({\n",
        "        \"Function\": func,\n",
        "        \"R2_mean_ttr\": scores.mean(),\n",
        "        \"R2_std_ttr\":  scores.std()\n",
        "    })\n",
        "\n",
        "df_ttr_perf = pd.DataFrame(results_ttr)\n",
        "print(df_ttr_perf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eyO2X7AeBdzT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, Matern, WhiteKernel\n",
        "\n",
        "# 1) Retrain one surrogate per function\n",
        "surrogates = {}\n",
        "for func, group in df_clean.groupby(\"Function\"):\n",
        "    mask = (df_clean[\"Function\"] == func)\n",
        "    Xf = X_imputed[mask]             # (n_f, 8) no NaNs\n",
        "    yf = group[\"Score\"].values\n",
        "\n",
        "    amp, ls = ga_cv.best_individual_\n",
        "    kernel = (\n",
        "        C(amp, (1e-3,1e3))\n",
        "        * Matern(length_scale=ls, length_scale_bounds=(1e-4,5), nu=1.5)\n",
        "        + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-5,1e1))\n",
        "    )\n",
        "    gp = GaussianProcessRegressor(\n",
        "        kernel=kernel,\n",
        "        normalize_y=True,\n",
        "        optimizer=None,\n",
        "        random_state=42\n",
        "    )\n",
        "    gp.fit(Xf, yf)\n",
        "    surrogates[func] = (gp, Xf.shape[1])\n",
        "\n",
        "# 2) Sample & rank\n",
        "N = 5000  # number of random samples per function\n",
        "k = 10    # how many top candidates to keep per function\n",
        "\n",
        "new_cands = []\n",
        "for func, (gp, dim) in surrogates.items():\n",
        "    CAND = np.random.rand(N, dim)\n",
        "    preds = gp.predict(CAND)\n",
        "    top_idx = np.argsort(preds)[-k:]      # indices of the k largest predictions\n",
        "\n",
        "    for j in top_idx:\n",
        "        vec = CAND[j]\n",
        "        new_cands.append({\n",
        "            \"Function\": func,\n",
        "            \"InputVec\": \"-\".join(f\"{x:.6f}\" for x in vec),\n",
        "            \"PredictedScore\": float(preds[j])\n",
        "        })\n",
        "\n",
        "df_new = pd.DataFrame(new_cands)\n",
        "# See your top-10 proposals per function:\n",
        "print(df_new.groupby(\"Function\").head(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e1YAU25LB9hy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, Matern, WhiteKernel\n",
        "\n",
        "new_cands = []\n",
        "N = 5000  # random samples per function\n",
        "k = 10    # top candidates to keep per function\n",
        "\n",
        "for func, group in df_clean.groupby(\"Function\"):\n",
        "    # 1) Rebuild Xf from the raw ParsedVec (no global padding)\n",
        "    #    Each parsed vector v is an array or list of length d_func\n",
        "    Xf = np.vstack(group[\"ParsedVec\"].values)  # shape (n_f, d_func)\n",
        "    yf = group[\"Score\"].values                 # shape (n_f,)\n",
        "\n",
        "    d = Xf.shape[1]  # true dimension for this function\n",
        "\n",
        "    # 2) Train a GP+Matern+White on this function’s data\n",
        "    amp, ls = ga_cv.best_individual_  # or you could have stored one per function\n",
        "    kernel = (\n",
        "        C(amp, (1e-3,1e3))\n",
        "        * Matern(length_scale=ls,\n",
        "                 length_scale_bounds=(1e-4, 5),\n",
        "                 nu=1.5)\n",
        "        + WhiteKernel(noise_level=1e-3,\n",
        "                      noise_level_bounds=(1e-5,1e1))\n",
        "    )\n",
        "    gp = GaussianProcessRegressor(\n",
        "        kernel=kernel,\n",
        "        normalize_y=True,\n",
        "        optimizer=None,\n",
        "        random_state=42\n",
        "    )\n",
        "    gp.fit(Xf, yf)\n",
        "\n",
        "    # 3) Sample and rank in the true d-dimensional unit cube\n",
        "    CAND = np.random.rand(N, d)\n",
        "    preds = gp.predict(CAND)\n",
        "    top_idx = np.argsort(preds)[-k:]  # best k\n",
        "\n",
        "    for j in top_idx:\n",
        "        vec = CAND[j]\n",
        "        new_cands.append({\n",
        "            \"Function\":     func,\n",
        "            \"InputVec\":     \"-\".join(f\"{x:.6f}\" for x in vec),\n",
        "            \"PredictedScore\": float(preds[j])\n",
        "        })\n",
        "\n",
        "# 4) Wrap up into a DataFrame and inspect\n",
        "df_new = pd.DataFrame(new_cands)\n",
        "print(df_new.groupby(\"Function\").head(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SXIEyRcXCQ1v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel as C, Matern, WhiteKernel\n",
        "\n",
        "new_cands = []\n",
        "N = 5000  # how many random samples per function\n",
        "k = 10    # how many top candidates to keep per function\n",
        "\n",
        "for func, group in df_clean.groupby(\"Function\"):\n",
        "    # 1) Build Xf by splitting the InputVec strings (no NaNs)\n",
        "    Xf = np.vstack([\n",
        "        np.fromiter(map(float, iv.split(\"-\")), dtype=float)\n",
        "        for iv in group[\"InputVec\"]\n",
        "    ])   # shape (n_rows, d_func)\n",
        "    yf = group[\"Score\"].values\n",
        "\n",
        "    d = Xf.shape[1]  # this function’s true dimensionality\n",
        "\n",
        "    # 2) Train a GP+Matern+White on this function’s own data\n",
        "    amp, ls = ga_cv.best_individual_  # or replace with per-func best if you stored that\n",
        "    kernel = (\n",
        "        C(amp, (1e-3,1e3))\n",
        "        * Matern(length_scale=ls, length_scale_bounds=(1e-4,5), nu=1.5)\n",
        "        + WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-5,1e1))\n",
        "    )\n",
        "    gp = GaussianProcessRegressor(\n",
        "        kernel=kernel,\n",
        "        normalize_y=True,\n",
        "        optimizer=None,\n",
        "        random_state=42\n",
        "    )\n",
        "    gp.fit(Xf, yf)\n",
        "\n",
        "    # 3) Sample N random points in [0,1]^d, predict, and pick top k\n",
        "    CAND = np.random.rand(N, d)\n",
        "    preds = gp.predict(CAND)\n",
        "    top_idx = np.argsort(preds)[-k:]  # indices of the k largest predictions\n",
        "\n",
        "    for j in top_idx:\n",
        "        vec = CAND[j]\n",
        "        new_cands.append({\n",
        "            \"Function\":        func,\n",
        "            \"InputVec\":        \"-\".join(f\"{x:.6f}\" for x in vec),\n",
        "            \"PredictedScore\":  float(preds[j])\n",
        "        })\n",
        "\n",
        "# 4) Collect into a DataFrame and inspect\n",
        "df_new = pd.DataFrame(new_cands)\n",
        "print(df_new.groupby(\"Function\").head(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EGLeUVbVCW9X"
      },
      "outputs": [],
      "source": [
        "# Pick the row with highest PredictedScore for each Function\n",
        "df_final = (\n",
        "    df_new\n",
        "    .loc[df_new.groupby(\"Function\")[\"PredictedScore\"].idxmax()]\n",
        "    .reset_index(drop=True)\n",
        "    [[\"Function\", \"InputVec\"]]\n",
        ")\n",
        "\n",
        "print(df_final)\n",
        "# And export if you like:\n",
        "df_final.to_csv(\"Round10_Final_Submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V_QzemHMDhQu"
      },
      "outputs": [],
      "source": [
        "df_final.to_csv(\"Round10_Final_Submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sNb1WVT_DuD0"
      },
      "outputs": [],
      "source": [
        "# from a code cell—this shells out to zip the notebook and CSV\n",
        "!zip submission_round10.zip Round10_Final_Submission.csv *.ipynb\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"submission_round10.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gskeg0zghSeg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzz7SxffhUAb"
      },
      "source": [
        "# New section \"Round 10+ Advanced Strategies (Bayesian Optimization, CMA-ES, LHS)\" round 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zlmu5QUbhXS4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# -------------------------------\n",
        "# ROUND 2–9 Best Queries and Scores per Function (Based on your latest notebook state)\n",
        "# -------------------------------\n",
        "\n",
        "queries_F1 = [\n",
        "    [0.944034, 0.625117],\n",
        "    [0.07314, 0.227123]\n",
        "]\n",
        "scores_F1 = [\n",
        "    1.3276592050304897e-69,\n",
        "    4.6015626100136584e-113\n",
        "]\n",
        "\n",
        "queries_F2 = [\n",
        "    [0.768771, 0.105777],\n",
        "    [0.768771, 0.105777]\n",
        "]\n",
        "scores_F2 = [\n",
        "    0.27308818432797793,\n",
        "    0.33828687086483444\n",
        "]\n",
        "\n",
        "queries_F3 = [\n",
        "    [0.1456, 0.944454, 0.638992],\n",
        "    [0.1856, 0.984454, 0.678992]\n",
        "]\n",
        "scores_F3 = [\n",
        "    -0.10726379301566011,\n",
        "    -0.05132522888449367\n",
        "]\n",
        "\n",
        "queries_F4 = [\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562],\n",
        "    [0.999363, 0.460618, 0.652742, 0.593562]\n",
        "]\n",
        "scores_F4 = [\n",
        "    -20.949420794091107,\n",
        "    -4.55517117590318\n",
        "]\n",
        "\n",
        "queries_F5 = [\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022],\n",
        "    [0.270636, 0.824504, 0.580542, 0.368022]\n",
        "]\n",
        "scores_F5 = [\n",
        "    13.377756436400528,\n",
        "    1105.1479642901527\n",
        "]\n",
        "\n",
        "queries_F6 = [\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],\n",
        "    [0.384874, 0.441523, 0.115493, 0.592513, 0.477029]\n",
        "]\n",
        "scores_F6 = [\n",
        "    -1.1857272137575898,\n",
        "    -0.5399068214874156\n",
        "]\n",
        "\n",
        "queries_F7 = [\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],\n",
        "    [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611]\n",
        "]\n",
        "scores_F7 = [\n",
        "    0.023506147714804363,\n",
        "    2.090579827192728\n",
        "]\n",
        "\n",
        "queries_F8 = [\n",
        "    [0.25682, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776],\n",
        "    [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776]\n",
        "]\n",
        "scores_F8 = [\n",
        "    8.3316420728934,\n",
        "    9.5659163853995\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# ROUND 10: Adding all new queries and observations\n",
        "# -------------------------------\n",
        "\n",
        "# F1 (2D)\n",
        "queries_F1 += [\n",
        "    [0.944034, 0.645117],\n",
        "    [0.07314, 0.227123]\n",
        "]\n",
        "scores_F1 += [\n",
        "    6.933250699386668e-70,\n",
        "    -1.560646704467778e-117\n",
        "]\n",
        "\n",
        "# F2 (2D)\n",
        "queries_F2 += [\n",
        "    [0.768771, 0.105777],\n",
        "    [0.768771, 0.105777],\n",
        "    [0.768771, 0.105777]\n",
        "]\n",
        "scores_F2 += [\n",
        "    0.09312933125476712,\n",
        "    0.23562706897099497,\n",
        "    0.5762427881544481\n",
        "]\n",
        "\n",
        "# F3 (3D)\n",
        "queries_F3 += [\n",
        "    [0.1856, 0.984454, 0.678992],\n",
        "    [0.1856, 0.984454, 0.678992],\n",
        "    [0.1456, 0.944454, 0.638992]\n",
        "]\n",
        "scores_F3 += [\n",
        "    -0.15237863681921446,\n",
        "    -0.14698930107649133,\n",
        "    -0.01882082499050317\n",
        "]\n",
        "\n",
        "# F4 (4D)\n",
        "queries_F4 += [\n",
        "    [0.999363, 0.460618, 0.652742, 0.593562],\n",
        "    [0.999363, 0.460618, 0.652742, 0.593562],\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562]\n",
        "]\n",
        "scores_F4 += [\n",
        "    -22.018089179607596,\n",
        "    -22.018089179607596,\n",
        "    -20.33439467922256\n",
        "]\n",
        "\n",
        "# F5 (4D)\n",
        "queries_F5 += [\n",
        "    [0.270636, 0.824504, 0.580542, 0.368022],\n",
        "    [0.270636, 0.824504, 0.580542, 0.368022],\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022]\n",
        "]\n",
        "scores_F5 += [\n",
        "    12.979330536136526,\n",
        "    12.979330536136526,\n",
        "    46.39060566194315\n",
        "]\n",
        "\n",
        "# F6 (5D)\n",
        "queries_F6 += [\n",
        "    [0.384874, 0.441523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.384874, 0.441523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.433609, 0.430291, 0.199161, 0.583735, 0.454637]\n",
        "]\n",
        "scores_F6 += [\n",
        "    -1.1838236564336748,\n",
        "    -1.263310156017569,\n",
        "    -1.0581335024921092\n",
        "]\n",
        "\n",
        "# F7 (6D)\n",
        "queries_F7 += [\n",
        "    [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611],\n",
        "    [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611],\n",
        "    [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611]\n",
        "]\n",
        "scores_F7 += [\n",
        "    0.03872554610994976,\n",
        "    0.03872554610994976,\n",
        "    1.5474127567590061\n",
        "]\n",
        "\n",
        "# F8 (8D)\n",
        "queries_F8 += [\n",
        "    [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "    [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "    [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776]\n",
        "]\n",
        "scores_F8 += [\n",
        "    7.3910313497699,\n",
        "    7.3910313497699,\n",
        "    8.316440887821\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# Final Sanity Check (optional)\n",
        "# -------------------------------\n",
        "print(f\"F1 queries: {len(queries_F1)}, scores: {len(scores_F1)}\")\n",
        "print(f\"F2 queries: {len(queries_F2)}, scores: {len(scores_F2)}\")\n",
        "print(f\"F3 queries: {len(queries_F3)}, scores: {len(scores_F3)}\")\n",
        "print(f\"F4 queries: {len(queries_F4)}, scores: {len(scores_F4)}\")\n",
        "print(f\"F5 queries: {len(queries_F5)}, scores: {len(scores_F5)}\")\n",
        "print(f\"F6 queries: {len(queries_F6)}, scores: {len(scores_F6)}\")\n",
        "print(f\"F7 queries: {len(queries_F7)}, scores: {len(scores_F7)}\")\n",
        "print(f\"F8 queries: {len(queries_F8)}, scores: {len(scores_F8)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ogcgp0Eif-v"
      },
      "source": [
        "Bayesian Optimization per function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ig_UwGvJiU98"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern\n",
        "from scipy.stats import norm, qmc\n",
        "import numpy as np\n",
        "\n",
        "def suggest_ei(X_hist, y_hist, n_suggest=2, samples=2000):\n",
        "    # Fit GP\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    # Candidates\n",
        "    sampler = qmc.LatinHypercube(d=X_hist.shape[1])\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "# Example for F3:\n",
        "X_hist_f3 = np.array(queries_F3)\n",
        "y_hist_f3 = np.array(scores_F3)\n",
        "suggestions_f3 = suggest_ei(X_hist_f3, y_hist_f3, n_suggest=2)\n",
        "print(\"Suggested next queries for F3:\", suggestions_f3)\n",
        "\n",
        "# You can repeat this for F2, F4, F6, F8:\n",
        "# X_hist_f2 = np.array(queries_F2)\n",
        "# y_hist_f2 = np.array(scores_F2)\n",
        "# suggestions_f2 = suggest_ei(X_hist_f2, y_hist_f2, n_suggest=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2Nk7EdCpioIS"
      },
      "outputs": [],
      "source": [
        "!pip install cma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iGrcs9B4ieGj"
      },
      "outputs": [],
      "source": [
        "import cma\n",
        "\n",
        "def suggest_cma_es(fitness_function, dim, x0=None, sigma0=0.3, popsize=8, n_generations=20):\n",
        "    if x0 is None:\n",
        "        x0 = np.random.uniform(0, 1, dim)\n",
        "    es = cma.CMAEvolutionStrategy(x0.tolist(), sigma0, {'popsize': popsize, 'bounds': [0, 1]})\n",
        "    es.optimize(fitness_function, iterations=n_generations)\n",
        "    return es.result.xbest\n",
        "\n",
        "# Example for F8\n",
        "X_hist_f8 = np.array(queries_F8)\n",
        "y_hist_f8 = np.array(scores_F8)\n",
        "\n",
        "# Fit GP surrogate for F8\n",
        "gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "gp.fit(X_hist_f8, y_hist_f8)\n",
        "\n",
        "# CMA-ES surrogate-driven optimizer\n",
        "def surrogate_neg(x):\n",
        "    return -gp.predict(np.array(x).reshape(1, -1))[0]\n",
        "\n",
        "best_cma_f8 = suggest_cma_es(surrogate_neg, dim=X_hist_f8.shape[1])\n",
        "print(\"Suggested next query for F8 (CMA-ES):\", best_cma_f8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML2oI_DIi7U0"
      },
      "source": [
        "LHS samples for F1 and F7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hq8goTIPjC4_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oT3dTTxfiy3L"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import qmc\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=5):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "# Example for F1 and F7\n",
        "lhs_f1 = suggest_lhs(dim=len(queries_F1[0]), n_suggest=5)\n",
        "lhs_f7 = suggest_lhs(dim=len(queries_F7[0]), n_suggest=5)\n",
        "\n",
        "print(\"LHS samples for F1:\", lhs_f1)\n",
        "print(\"LHS samples for F7:\", lhs_f7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L7b_zdmkjMKT"
      },
      "outputs": [],
      "source": [
        " LOOP FULL CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hWEGy1_GjDxM"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern\n",
        "from scipy.stats import norm, qmc\n",
        "import cma\n",
        "import numpy as np\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def suggest_ei(X_hist, y_hist, n_suggest=1, samples=2000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=X_hist.shape[1])\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_cma_es(fitness_function, dim, x0=None, sigma0=0.3, popsize=8, n_generations=20):\n",
        "    if x0 is None:\n",
        "        x0 = np.random.uniform(0, 1, dim)\n",
        "    es = cma.CMAEvolutionStrategy(x0.tolist(), sigma0, {'popsize': popsize, 'bounds': [0, 1]})\n",
        "    es.optimize(fitness_function, iterations=n_generations)\n",
        "    return es.result.xbest\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=5):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# --- Strategy Allocation per Function ---\n",
        "\n",
        "final_queries = []\n",
        "\n",
        "# F1 - LHS only (plateau)\n",
        "lhs_f1 = suggest_lhs(dim=len(queries_F1[0]), n_suggest=5)\n",
        "final_queries.extend([format_query(q) for q in lhs_f1])\n",
        "\n",
        "# F2 - BO\n",
        "suggestions_f2 = suggest_ei(np.array(queries_F2), np.array(scores_F2), n_suggest=1)\n",
        "final_queries.append(format_query(suggestions_f2[0]))\n",
        "\n",
        "# F3 - BO\n",
        "suggestions_f3 = suggest_ei(np.array(queries_F3), np.array(scores_F3), n_suggest=1)\n",
        "final_queries.append(format_query(suggestions_f3[0]))\n",
        "\n",
        "# F4 - BO\n",
        "suggestions_f4 = suggest_ei(np.array(queries_F4), np.array(scores_F4), n_suggest=1)\n",
        "final_queries.append(format_query(suggestions_f4[0]))\n",
        "\n",
        "# F5 - Skip (already optimized enough)\n",
        "\n",
        "# F6 - BO + CMA-ES\n",
        "suggestions_f6 = suggest_ei(np.array(queries_F6), np.array(scores_F6), n_suggest=1)\n",
        "gp_f6 = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "gp_f6.fit(np.array(queries_F6), np.array(scores_F6))\n",
        "best_cma_f6 = suggest_cma_es(lambda x: -gp_f6.predict(np.array(x).reshape(1, -1))[0], dim=len(queries_F6[0]))\n",
        "final_queries.append(format_query(suggestions_f6[0]))\n",
        "final_queries.append(format_query(best_cma_f6))\n",
        "\n",
        "# F7 - LHS only (plateau)\n",
        "lhs_f7 = suggest_lhs(dim=len(queries_F7[0]), n_suggest=5)\n",
        "final_queries.extend([format_query(q) for q in lhs_f7])\n",
        "\n",
        "# F8 - BO + CMA-ES + LHS\n",
        "suggestions_f8 = suggest_ei(np.array(queries_F8), np.array(scores_F8), n_suggest=1)\n",
        "gp_f8 = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "gp_f8.fit(np.array(queries_F8), np.array(scores_F8))\n",
        "best_cma_f8 = suggest_cma_es(lambda x: -gp_f8.predict(np.array(x).reshape(1, -1))[0], dim=len(queries_F8[0]))\n",
        "lhs_f8 = suggest_lhs(dim=len(queries_F8[0]), n_suggest=3)\n",
        "final_queries.append(format_query(suggestions_f8[0]))\n",
        "final_queries.append(format_query(best_cma_f8))\n",
        "final_queries.extend([format_query(q) for q in lhs_f8])\n",
        "\n",
        "# --- Export Submission File ---\n",
        "\n",
        "with open('formatted_submission_round11.txt', 'w') as f:\n",
        "    for q in final_queries:\n",
        "        f.write(q + '\\n')\n",
        "\n",
        "print(f\"✅ Submission file 'formatted_submission_round11.txt' created with {len(final_queries)} queries.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TJFQi2j_j1bb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern\n",
        "from scipy.stats import norm, qmc\n",
        "import cma\n",
        "\n",
        "# -----------------------------------------\n",
        "# Load ALL Queries and Scores (Rounds 2–10)\n",
        "# -----------------------------------------\n",
        "queries_F1 = [\n",
        "    [0.944034, 0.625117], [0.07314, 0.227123], [0.944034, 0.645117], [0.07314, 0.227123]\n",
        "]\n",
        "scores_F1 = [\n",
        "    1.3276592050304897e-69, 4.6015626100136584e-113, 6.933250699386668e-70, -1.560646704467778e-117\n",
        "]\n",
        "\n",
        "queries_F2 = [\n",
        "    [0.768771, 0.105777], [0.768771, 0.105777], [0.768771, 0.105777], [0.768771, 0.105777], [0.768771, 0.105777]\n",
        "]\n",
        "scores_F2 = [\n",
        "    0.27308818432797793, 0.33828687086483444, 0.09312933125476712, 0.23562706897099497, 0.5762427881544481\n",
        "]\n",
        "\n",
        "queries_F3 = [\n",
        "    [0.1456, 0.944454, 0.638992], [0.1856, 0.984454, 0.678992], [0.1856, 0.984454, 0.678992], [0.1456, 0.944454, 0.638992], [0.1856, 0.984454, 0.678992]\n",
        "]\n",
        "scores_F3 = [\n",
        "    -0.10726379301566011, -0.05132522888449367, -0.15237863681921446, -0.14698930107649133, -0.01882082499050317\n",
        "]\n",
        "\n",
        "queries_F4 = [\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562], [0.999363, 0.460618, 0.652742, 0.593562], [0.999363, 0.460618, 0.652742, 0.593562], [0.999363, 0.440618, 0.632742, 0.573562], [0.999363, 0.460618, 0.652742, 0.593562]\n",
        "]\n",
        "scores_F4 = [\n",
        "    -20.949420794091107, -4.55517117590318, -22.018089179607596, -22.018089179607596, -20.33439467922256\n",
        "]\n",
        "\n",
        "queries_F5 = [\n",
        "    [0.290636, 0.824504, 0.580542, 0.368022], [0.270636, 0.824504, 0.580542, 0.368022], [0.270636, 0.824504, 0.580542, 0.368022], [0.290636, 0.824504, 0.580542, 0.368022], [0.270636, 0.824504, 0.580542, 0.368022]\n",
        "]\n",
        "scores_F5 = [\n",
        "    13.377756436400528, 1105.1479642901527, 12.979330536136526, 12.979330536136526, 46.39060566194315\n",
        "]\n",
        "\n",
        "queries_F6 = [\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029], [0.384874, 0.441523, 0.115493, 0.592513, 0.477029], [0.384874, 0.441523, 0.115493, 0.592513, 0.477029], [0.433609, 0.430291, 0.199161, 0.583735, 0.454637], [0.384874, 0.441523, 0.115493, 0.592513, 0.477029]\n",
        "]\n",
        "scores_F6 = [\n",
        "    -1.1857272137575898, -0.5399068214874156, -1.1838236564336748, -1.263310156017569, -1.0581335024921092\n",
        "]\n",
        "\n",
        "queries_F7 = [\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193], [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611], [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611], [0.94976, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611], [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193]\n",
        "]\n",
        "scores_F7 = [\n",
        "    0.023506147714804363, 2.090579827192728, 0.03872554610994976, 0.03872554610994976, 1.5474127567590061\n",
        "]\n",
        "\n",
        "queries_F8 = [\n",
        "    [0.25682, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776], [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776], [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776], [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776], [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776]\n",
        "]\n",
        "scores_F8 = [\n",
        "    8.3316420728934, 9.5659163853995, 7.3910313497699, 7.3910313497699, 8.316440887821\n",
        "]\n",
        "\n",
        "# -----------------------------------------\n",
        "# Smart Loop (BO + CMA-ES + LHS)\n",
        "# -----------------------------------------\n",
        "def suggest_ei(X_hist, y_hist, n_suggest=1, samples=2000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=X_hist.shape[1])\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_cma_es(fitness_function, dim, x0=None, sigma0=0.3, popsize=8, n_generations=20):\n",
        "    if x0 is None:\n",
        "        x0 = np.random.uniform(0, 1, dim)\n",
        "    es = cma.CMAEvolutionStrategy(x0.tolist(), sigma0, {'popsize': popsize, 'bounds': [0, 1]})\n",
        "    es.optimize(fitness_function, iterations=n_generations)\n",
        "    return es.result.xbest\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=5):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "final_queries = []\n",
        "\n",
        "lhs_f1 = suggest_lhs(dim=len(queries_F1[0]), n_suggest=5)\n",
        "final_queries.extend([format_query(q) for q in lhs_f1])\n",
        "\n",
        "suggestions_f2 = suggest_ei(np.array(queries_F2), np.array(scores_F2), n_suggest=1)\n",
        "final_queries.append(format_query(suggestions_f2[0]))\n",
        "\n",
        "suggestions_f3 = suggest_ei(np.array(queries_F3), np.array(scores_F3), n_suggest=1)\n",
        "final_queries.append(format_query(suggestions_f3[0]))\n",
        "\n",
        "suggestions_f4 = suggest_ei(np.array(queries_F4), np.array(scores_F4), n_suggest=1)\n",
        "final_queries.append(format_query(suggestions_f4[0]))\n",
        "\n",
        "suggestions_f6 = suggest_ei(np.array(queries_F6), np.array(scores_F6), n_suggest=1)\n",
        "gp_f6 = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "gp_f6.fit(np.array(queries_F6), np.array(scores_F6))\n",
        "best_cma_f6 = suggest_cma_es(lambda x: -gp_f6.predict(np.array(x).reshape(1, -1))[0], dim=len(queries_F6[0]))\n",
        "final_queries.append(format_query(suggestions_f6[0]))\n",
        "final_queries.append(format_query(best_cma_f6))\n",
        "\n",
        "lhs_f7 = suggest_lhs(dim=len(queries_F7[0]), n_suggest=5)\n",
        "final_queries.extend([format_query(q) for q in lhs_f7])\n",
        "\n",
        "suggestions_f8 = suggest_ei(np.array(queries_F8), np.array(scores_F8), n_suggest=1)\n",
        "gp_f8 = GaussianProcessRegressor(kernel=Matern(nu=2.5), alpha=1e-6, normalize_y=True)\n",
        "gp_f8.fit(np.array(queries_F8), np.array(scores_F8))\n",
        "best_cma_f8 = suggest_cma_es(lambda x: -gp_f8.predict(np.array(x).reshape(1, -1))[0], dim=len(queries_F8[0]))\n",
        "lhs_f8 = suggest_lhs(dim=len(queries_F8[0]), n_suggest=3)\n",
        "final_queries.append(format_query(suggestions_f8[0]))\n",
        "final_queries.append(format_query(best_cma_f8))\n",
        "final_queries.extend([format_query(q) for q in lhs_f8])\n",
        "\n",
        "# Display all queries\n",
        "final_queries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Initial Data Integration."
      ],
      "metadata": {
        "id": "jD3W489yziIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Round 10b - Integration of Second Initial Data  \n",
        "In Round 10b, we integrated the new batch of initial queries provided by the capstone team into our Round 10 pipeline.  \n",
        "This allows us to retrain our surrogates on an expanded dataset and test if the newly provided data changes our proposal engine outputs.\n"
      ],
      "metadata": {
        "id": "ug8JaUWmztMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Upload your zipped initial_data2.zip\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "o7FJP5Nq0esy",
        "outputId": "3cb0aab7-0c1c-462f-d25a-5825fbfa8693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a279d59f-e236-430b-9fc8-91120997b47e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a279d59f-e236-430b-9fc8-91120997b47e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IMP-PCMLAI-capstone-second-set-of-initial_data.zip to IMP-PCMLAI-capstone-second-set-of-initial_data (1).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('IMP-PCMLAI-capstone-second-set-of-initial_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('initial_data2')\n",
        "\n",
        "print(\"✅ Folder extracted as 'initial_data2'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlchnM3k0rAy",
        "outputId": "784887f5-6e01-4dd1-c447-0205b6f2d72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Folder extracted as 'initial_data2'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(\"initial_data2\"):\n",
        "    print(f\"📂 {root}\")\n",
        "    for file in files:\n",
        "        print(f\"   └── {file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTllXqyf1m9X",
        "outputId": "bb33e233-9a86-4365-8a0b-6d4eea424641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 initial_data2\n",
            "📂 initial_data2/__MACOSX\n",
            "   └── ._initial_data2\n",
            "📂 initial_data2/__MACOSX/initial_data2\n",
            "   └── ._function_3\n",
            "   └── ._function_5\n",
            "   └── ._function_4\n",
            "   └── ._function_7\n",
            "   └── ._function_6\n",
            "   └── ._function_2\n",
            "   └── ._function_8\n",
            "   └── ._function_1\n",
            "📂 initial_data2/initial_data2\n",
            "📂 initial_data2/initial_data2/function_8\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_5\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_7\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_4\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_1\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_6\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_3\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n",
            "📂 initial_data2/initial_data2/function_2\n",
            "   └── initial_outputs.npy\n",
            "   └── initial_inputs.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "from scipy.stats import norm, qmc\n",
        "import cma\n",
        "\n",
        "# --- Expected dimensions per function ---\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "\n",
        "# --- Step 1: Reload clean second initial data ONLY ---\n",
        "root_folder = 'initial_data2/initial_data2'\n",
        "queries = {}\n",
        "scores = {}\n",
        "\n",
        "for f_index in range(1, 9):\n",
        "    f_name = f'F{f_index}'\n",
        "    f_folder = f'{root_folder}/function_{f_index}'\n",
        "\n",
        "    # Load clean data\n",
        "    inputs = np.load(f'{f_folder}/initial_inputs.npy')\n",
        "    outputs = np.load(f'{f_folder}/initial_outputs.npy')\n",
        "\n",
        "    # Store clean in dictionaries\n",
        "    queries[f_name] = inputs\n",
        "    scores[f_name] = outputs\n",
        "\n",
        "    # Check dimensions\n",
        "    assert inputs.shape[1] == expected_dims[f_name], f\"Dimension mismatch in {f_name}\"\n",
        "\n",
        "print(\"✅ Clean isolated datasets loaded and verified per function.\")\n",
        "\n",
        "# --- Step 2: Safe query suggestion functions ---\n",
        "def suggest_ei_safe(dim, X_hist, y_hist, n_suggest=1, samples=10000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=1.5) + WhiteKernel(noise_level=1e-6), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=1):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# --- Step 3: Generate clean Round 10b submission ---\n",
        "final_queries_10b_clean = []\n",
        "\n",
        "# F1 and F7 - Pure LHS (correct dimensions)\n",
        "for f in ['F1', 'F7']:\n",
        "    lhs = suggest_lhs(dim=expected_dims[f], n_suggest=1)\n",
        "    final_queries_10b_clean.append(format_query(lhs[0]))\n",
        "\n",
        "# F2–F5 - EI (safe dimension enforcement)\n",
        "for f in ['F2', 'F3', 'F4', 'F5']:\n",
        "    dim = expected_dims[f]\n",
        "    suggestion = suggest_ei_safe(dim, queries[f], scores[f], n_suggest=1)\n",
        "    final_queries_10b_clean.append(format_query(suggestion[0]))\n",
        "\n",
        "# F6 & F8 - EI (safe dimension enforcement)\n",
        "for f in ['F6', 'F8']:\n",
        "    dim = expected_dims[f]\n",
        "    suggestion = suggest_ei_safe(dim, queries[f], scores[f], n_suggest=1)\n",
        "    final_queries_10b_clean.append(format_query(suggestion[0]))\n",
        "\n",
        "# Confirm output\n",
        "print(\"✅ Clean Round 10b submission (1 per function F1–F8):\")\n",
        "for i, q in enumerate(final_queries_10b_clean):\n",
        "    print(f\"F{i+1}: {q}\")\n",
        "\n",
        "# --- Step 4: Save clean submission ---\n",
        "submission_file_10b_clean = 'formatted_submission_round10b_clean.txt'\n",
        "with open(submission_file_10b_clean, 'w') as f:\n",
        "    for line in final_queries_10b_clean:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(f\"\\n✅ Clean and dimension-forced submission file created: {submission_file_10b_clean}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXHiLyBp4ZC1",
        "outputId": "a6429425-5adf-4b6d-e4ac-df9492dc3cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean isolated datasets loaded and verified per function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean Round 10b submission (1 per function F1–F8):\n",
            "F1: 0.154736-0.580622\n",
            "F2: 0.148799-0.233206-0.942751-0.737382-0.076690-0.333501\n",
            "F3: 0.309781-0.054693\n",
            "F4: 0.858120-0.694383-0.741292\n",
            "F5: 0.346940-0.417577-0.354331-0.507312\n",
            "F6: 0.152870-0.636437-0.526862-0.752732\n",
            "F7: 0.987589-0.643668-0.575757-0.721036-0.569814\n",
            "F8: 0.024319-0.254796-0.136871-0.124977-0.454085-0.548966-0.104045-0.528358\n",
            "\n",
            "✅ Clean and dimension-forced submission file created: formatted_submission_round10b_clean.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f_index in range(1, 9):\n",
        "    f_folder = f'initial_data2/initial_data2/function_{f_index}'\n",
        "    inputs = np.load(f'{f_folder}/initial_inputs.npy')\n",
        "    print(f\"F{f_index} inputs shape: {inputs.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT5TJbaW4jHf",
        "outputId": "b3254434-9d36-49e5-e7da-9e2c76998ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 inputs shape: (20, 2)\n",
            "F2 inputs shape: (10, 2)\n",
            "F3 inputs shape: (15, 3)\n",
            "F4 inputs shape: (30, 4)\n",
            "F5 inputs shape: (20, 4)\n",
            "F6 inputs shape: (20, 5)\n",
            "F7 inputs shape: (30, 6)\n",
            "F8 inputs shape: (40, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rerun this to recreate your file from final_queries_10b_clean\n",
        "with open('formatted_submission_round10b_clean.txt', 'w') as f:\n",
        "    for line in final_queries_10b_clean:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(\"✅ Clean submission file recreated: formatted_submission_round10b_clean.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfNgjhOq4wP_",
        "outputId": "817d9336-b7e7-42ae-e3c2-8ad84e6d7aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean submission file recreated: formatted_submission_round10b_clean.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "from scipy.stats import norm, qmc\n",
        "\n",
        "# --- Expected dimensions per function ---\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "\n",
        "# --- Load clean data ---\n",
        "root_folder = 'initial_data2/initial_data2'\n",
        "queries = {}\n",
        "scores = {}\n",
        "\n",
        "for f_index in range(1, 9):\n",
        "    f_name = f'F{f_index}'\n",
        "    f_folder = f'{root_folder}/function_{f_index}'\n",
        "    inputs = np.load(f'{f_folder}/initial_inputs.npy')\n",
        "    outputs = np.load(f'{f_folder}/initial_outputs.npy')\n",
        "    queries[f_name] = inputs\n",
        "    scores[f_name] = outputs\n",
        "    assert inputs.shape[1] == expected_dims[f_name], f\"Dimension mismatch in {f_name}\"\n",
        "\n",
        "print(\"✅ Clean isolated datasets loaded and verified per function.\\n\")\n",
        "\n",
        "# --- Safe suggestion functions ---\n",
        "def suggest_ei_safe(dim, X_hist, y_hist, n_suggest=1, samples=10000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=1.5) + WhiteKernel(noise_level=1e-6), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=1):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# --- Generate queries ---\n",
        "final_queries_10b_clean = []\n",
        "\n",
        "for f in ['F1', 'F7']:\n",
        "    lhs = suggest_lhs(dim=expected_dims[f], n_suggest=1)\n",
        "    final_queries_10b_clean.append(format_query(lhs[0]))\n",
        "\n",
        "for f in ['F2', 'F3', 'F4', 'F5', 'F6', 'F8']:\n",
        "    dim = expected_dims[f]\n",
        "    suggestion = suggest_ei_safe(dim, queries[f], scores[f], n_suggest=1)\n",
        "    final_queries_10b_clean.append(format_query(suggestion[0]))\n",
        "\n",
        "# --- Save ---\n",
        "submission_file_10b_clean = 'formatted_submission_round10b_clean.txt'\n",
        "with open(submission_file_10b_clean, 'w') as f:\n",
        "    for line in final_queries_10b_clean:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(f\"✅ Clean and dimension-forced submission file created: {submission_file_10b_clean}\\n\")\n",
        "\n",
        "# --- Validate and print ---\n",
        "def validate_submission_format_and_print(filename):\n",
        "    valid = True\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    if len(lines) != 8:\n",
        "        print(f\"❌ ERROR: Submission file should have exactly 8 lines, found {len(lines)}.\")\n",
        "        valid = False\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        num_values = line.count('-') + 1\n",
        "        expected = list(expected_dims.values())[i]\n",
        "        print(f\"F{i+1}: {line}  -->  {num_values} values (Expected: {expected})\")\n",
        "        if num_values != expected:\n",
        "            print(f\"❌ ERROR: Line {i+1} (F{i+1}) has wrong number of values.\")\n",
        "            valid = False\n",
        "\n",
        "    if valid:\n",
        "        print(\"\\n✅ Submission file passed all strict validation checks (8 lines, correct dimensions, clean format).\")\n",
        "    else:\n",
        "        print(\"\\n❌ Issues found. Please correct the file before submission.\")\n",
        "\n",
        "# Run validation\n",
        "validate_submission_format_and_print(submission_file_10b_clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-zKSygN5A65",
        "outputId": "b107aac9-4af0-4065-dbc7-13ff2f48afb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean isolated datasets loaded and verified per function.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Clean and dimension-forced submission file created: formatted_submission_round10b_clean.txt\n",
            "\n",
            "F1: 0.026652-0.513638  -->  2 values (Expected: 2)\n",
            "F2: 0.246985-0.760921-0.909485-0.444078-0.877780-0.529697  -->  6 values (Expected: 2)\n",
            "❌ ERROR: Line 2 (F2) has wrong number of values.\n",
            "F3: 0.736713-0.154028  -->  2 values (Expected: 3)\n",
            "❌ ERROR: Line 3 (F3) has wrong number of values.\n",
            "F4: 0.192789-0.044596-0.529195  -->  3 values (Expected: 4)\n",
            "❌ ERROR: Line 4 (F4) has wrong number of values.\n",
            "F5: 0.272172-0.418113-0.345078-0.505945  -->  4 values (Expected: 4)\n",
            "F6: 0.423388-0.591971-0.547197-0.567750  -->  4 values (Expected: 5)\n",
            "❌ ERROR: Line 6 (F6) has wrong number of values.\n",
            "F7: 0.067956-0.357918-0.447384-0.963809-0.924844  -->  5 values (Expected: 6)\n",
            "❌ ERROR: Line 7 (F7) has wrong number of values.\n",
            "F8: 0.063103-0.075034-0.147500-0.059923-0.679779-0.486507-0.016103-0.520590  -->  8 values (Expected: 8)\n",
            "\n",
            "❌ Issues found. Please correct the file before submission.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hardcoded clean block with enforced correct dimensions per function\n",
        "\n",
        "final_queries_10b_clean = []\n",
        "\n",
        "# F1 - LHS\n",
        "lhs_f1 = suggest_lhs(2, 1)\n",
        "final_queries_10b_clean.append(format_query(lhs_f1[0]))\n",
        "\n",
        "# F2 - EI Safe\n",
        "ei_f2 = suggest_ei_safe(2, queries['F2'], scores['F2'], 1)\n",
        "final_queries_10b_clean.append(format_query(ei_f2[0]))\n",
        "\n",
        "# F3 - EI Safe\n",
        "ei_f3 = suggest_ei_safe(3, queries['F3'], scores['F3'], 1)\n",
        "final_queries_10b_clean.append(format_query(ei_f3[0]))\n",
        "\n",
        "# F4 - EI Safe\n",
        "ei_f4 = suggest_ei_safe(4, queries['F4'], scores['F4'], 1)\n",
        "final_queries_10b_clean.append(format_query(ei_f4[0]))\n",
        "\n",
        "# F5 - EI Safe\n",
        "ei_f5 = suggest_ei_safe(4, queries['F5'], scores['F5'], 1)\n",
        "final_queries_10b_clean.append(format_query(ei_f5[0]))\n",
        "\n",
        "# F6 - EI Safe\n",
        "ei_f6 = suggest_ei_safe(5, queries['F6'], scores['F6'], 1)\n",
        "final_queries_10b_clean.append(format_query(ei_f6[0]))\n",
        "\n",
        "# F7 - LHS\n",
        "lhs_f7 = suggest_lhs(6, 1)\n",
        "final_queries_10b_clean.append(format_query(lhs_f7[0]))\n",
        "\n",
        "# F8 - EI Safe\n",
        "ei_f8 = suggest_ei_safe(8, queries['F8'], scores['F8'], 1)\n",
        "final_queries_10b_clean.append(format_query(ei_f8[0]))\n",
        "\n",
        "# --- Save ---\n",
        "submission_file_10b_clean = 'formatted_submission_round10b_clean.txt'\n",
        "with open(submission_file_10b_clean, 'w') as f:\n",
        "    for line in final_queries_10b_clean:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(\"✅ Submission file recreated.\")\n",
        "\n",
        "# --- Validate and print ---\n",
        "validate_submission_format_and_print(submission_file_10b_clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqgk0p4-5NMV",
        "outputId": "52ead7e1-b7ce-4df4-e209-fca0fb2c03e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission file recreated.\n",
            "F1: 0.299067-0.165444  -->  2 values (Expected: 2)\n",
            "F2: 0.516638-0.675606  -->  2 values (Expected: 2)\n",
            "F3: 0.545939-0.026068-0.337518  -->  3 values (Expected: 3)\n",
            "F4: 0.310098-0.365623-0.397439-0.511497  -->  4 values (Expected: 4)\n",
            "F5: 0.697139-0.863625-0.802958-0.004318  -->  4 values (Expected: 4)\n",
            "F6: 0.572663-0.944633-0.098631-0.990648-0.022670  -->  5 values (Expected: 5)\n",
            "F7: 0.812471-0.064564-0.569280-0.660293-0.814823-0.906764  -->  6 values (Expected: 6)\n",
            "F8: 0.094126-0.103311-0.031557-0.156631-0.600022-0.417871-0.077991-0.839494  -->  8 values (Expected: 8)\n",
            "\n",
            "✅ Submission file passed all strict validation checks (8 lines, correct dimensions, clean format).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "from scipy.stats import norm, qmc\n",
        "\n",
        "# --- Expected dimensions per function ---\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "\n",
        "# --- Step 1: Load previous rounds queries and scores (ensure you load your own data) ---\n",
        "# Replace the following placeholders with your own lists from past rounds:\n",
        "# Example: queries_F1 = [[...], [...], ...]   scores_F1 = [score1, score2, ...]\n",
        "# You must ensure these are the FULL cumulative historical queries and scores.\n",
        "\n",
        "# For demonstration only, let's create empty placeholders:\n",
        "queries_F = {f'F{i}': [] for i in range(1, 9)}\n",
        "scores_F = {f'F{i}': [] for i in range(1, 9)}\n",
        "\n",
        "# --- Step 2: Load and append new initial data ---\n",
        "root_folder = 'initial_data2/initial_data2'\n",
        "\n",
        "for f_index in range(1, 9):\n",
        "    f_name = f'F{f_index}'\n",
        "    f_folder = f'{root_folder}/function_{f_index}'\n",
        "    new_inputs = np.load(f'{f_folder}/initial_inputs.npy')\n",
        "    new_outputs = np.load(f'{f_folder}/initial_outputs.npy')\n",
        "    queries_F[f_name] += new_inputs.tolist()\n",
        "    scores_F[f_name] += new_outputs.tolist()\n",
        "    assert np.array(queries_F[f_name]).shape[1] == expected_dims[f_name], f\"Dimension mismatch in {f_name}\"\n",
        "\n",
        "print(\"✅ All rounds and new data successfully integrated per function.\\n\")\n",
        "\n",
        "# --- Step 3: Safe suggestion functions ---\n",
        "def suggest_ei_safe(dim, X_hist, y_hist, n_suggest=1, samples=10000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=1.5) + WhiteKernel(noise_level=1e-6), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=1):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# --- Step 4: Generate queries ---\n",
        "final_queries_10b_clean = []\n",
        "\n",
        "# F1 and F7 - LHS only\n",
        "lhs_f1 = suggest_lhs(2, 1)\n",
        "final_queries_10b_clean.append(format_query(lhs_f1[0]))\n",
        "\n",
        "lhs_f7 = suggest_lhs(6, 1)\n",
        "final_queries_10b_clean.append(format_query(lhs_f7[0]))\n",
        "\n",
        "# F2–F5, F6, F8 - EI after retraining on full history\n",
        "for f in ['F2', 'F3', 'F4', 'F5', 'F6', 'F8']:\n",
        "    dim = expected_dims[f]\n",
        "    X_hist = np.array(queries_F[f])\n",
        "    y_hist = np.array(scores_F[f])\n",
        "    suggestion = suggest_ei_safe(dim, X_hist, y_hist, n_suggest=1)\n",
        "    final_queries_10b_clean.append(format_query(suggestion[0]))\n",
        "\n",
        "# --- Step 5: Save submission ---\n",
        "submission_file_10b_clean = 'formatted_submission_round10b_clean.txt'\n",
        "with open(submission_file_10b_clean, 'w') as f:\n",
        "    for line in final_queries_10b_clean:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(\"✅ Submission file created: formatted_submission_round10b_clean.txt\\n\")\n",
        "\n",
        "# --- Step 6: Validate and print ---\n",
        "def validate_submission_format_and_print(filename):\n",
        "    valid = True\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    if len(lines) != 8:\n",
        "        print(f\"❌ ERROR: Submission file should have exactly 8 lines, found {len(lines)}.\")\n",
        "        valid = False\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        num_values = line.count('-') + 1\n",
        "        expected = list(expected_dims.values())[i]\n",
        "        print(f\"F{i+1}: {line}  -->  {num_values} values (Expected: {expected})\")\n",
        "        if num_values != expected:\n",
        "            print(f\"❌ ERROR: Line {i+1} (F{i+1}) has wrong number of values.\")\n",
        "            valid = False\n",
        "\n",
        "    if valid:\n",
        "        print(\"\\n✅ Submission file passed all strict validation checks (8 lines, correct dimensions, clean format).\")\n",
        "    else:\n",
        "        print(\"\\n❌ Issues found. Please correct the file before submission.\")\n",
        "\n",
        "validate_submission_format_and_print(submission_file_10b_clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUKf0G-p5w37",
        "outputId": "f371e29c-e9d2-4460-c7e9-c91010195253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All rounds and new data successfully integrated per function.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission file created: formatted_submission_round10b_clean.txt\n",
            "\n",
            "F1: 0.783216-0.655134  -->  2 values (Expected: 2)\n",
            "F2: 0.518400-0.952677-0.681280-0.277810-0.865838-0.030272  -->  6 values (Expected: 2)\n",
            "❌ ERROR: Line 2 (F2) has wrong number of values.\n",
            "F3: 0.565266-0.548775  -->  2 values (Expected: 3)\n",
            "❌ ERROR: Line 3 (F3) has wrong number of values.\n",
            "F4: 0.195510-0.196283-0.621999  -->  3 values (Expected: 4)\n",
            "❌ ERROR: Line 4 (F4) has wrong number of values.\n",
            "F5: 0.363661-0.406324-0.375193-0.431906  -->  4 values (Expected: 4)\n",
            "F6: 0.252818-0.946147-0.487879-0.300221  -->  4 values (Expected: 5)\n",
            "❌ ERROR: Line 6 (F6) has wrong number of values.\n",
            "F7: 0.627421-0.706013-0.895323-0.701697-0.114611  -->  5 values (Expected: 6)\n",
            "❌ ERROR: Line 7 (F7) has wrong number of values.\n",
            "F8: 0.048262-0.042542-0.089672-0.125161-0.783651-0.436627-0.181279-0.416319  -->  8 values (Expected: 8)\n",
            "\n",
            "❌ Issues found. Please correct the file before submission.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "from scipy.stats import norm, qmc\n",
        "\n",
        "# --- Expected dimensions ---\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "\n",
        "# --- Step 1: Load only clean, known data ---\n",
        "root_folder = 'initial_data2/initial_data2'\n",
        "clean_data_per_function = {}\n",
        "\n",
        "for f_index in range(1, 9):\n",
        "    f_name = f'F{f_index}'\n",
        "    f_folder = f'{root_folder}/function_{f_index}'\n",
        "    inputs = np.load(f'{f_folder}/initial_inputs.npy')\n",
        "    outputs = np.load(f'{f_folder}/initial_outputs.npy')\n",
        "    # Clean dimension check\n",
        "    assert inputs.shape[1] == expected_dims[f_name], f\"Dimension mismatch in {f_name}\"\n",
        "    clean_data_per_function[f_name] = {'queries': inputs, 'scores': outputs}\n",
        "\n",
        "print(\"✅ Loaded clean, isolated datasets per function.\\n\")\n",
        "\n",
        "# --- Suggestion helpers ---\n",
        "def suggest_ei_safe(dim, X_hist, y_hist, n_suggest=1, samples=10000):\n",
        "    assert X_hist.shape[1] == dim, f\"Dataset mismatch inside suggest_ei_safe (expected {dim})\"\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=1.5) + WhiteKernel(noise_level=1e-6), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_lhs(dim, n_suggest=1):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_suggest)\n",
        "    return samples\n",
        "\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# --- Step 2: Generate per function safely ---\n",
        "final_queries_10b_clean = []\n",
        "\n",
        "# F1 - Pure LHS\n",
        "f1_query = suggest_lhs(2, 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f1_query))\n",
        "\n",
        "# F2 - EI on clean data\n",
        "f2_query = suggest_ei_safe(2, clean_data_per_function['F2']['queries'], clean_data_per_function['F2']['scores'], 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f2_query))\n",
        "\n",
        "# F3\n",
        "f3_query = suggest_ei_safe(3, clean_data_per_function['F3']['queries'], clean_data_per_function['F3']['scores'], 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f3_query))\n",
        "\n",
        "# F4\n",
        "f4_query = suggest_ei_safe(4, clean_data_per_function['F4']['queries'], clean_data_per_function['F4']['scores'], 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f4_query))\n",
        "\n",
        "# F5\n",
        "f5_query = suggest_ei_safe(4, clean_data_per_function['F5']['queries'], clean_data_per_function['F5']['scores'], 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f5_query))\n",
        "\n",
        "# F6\n",
        "f6_query = suggest_ei_safe(5, clean_data_per_function['F6']['queries'], clean_data_per_function['F6']['scores'], 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f6_query))\n",
        "\n",
        "# F7 - Pure LHS\n",
        "f7_query = suggest_lhs(6, 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f7_query))\n",
        "\n",
        "# F8\n",
        "f8_query = suggest_ei_safe(8, clean_data_per_function['F8']['queries'], clean_data_per_function['F8']['scores'], 1)[0]\n",
        "final_queries_10b_clean.append(format_query(f8_query))\n",
        "\n",
        "# --- Step 3: Save ---\n",
        "submission_file_10b_clean = 'formatted_submission_round10b_clean.txt'\n",
        "with open(submission_file_10b_clean, 'w') as f:\n",
        "    for line in final_queries_10b_clean:\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "print(\"✅ Submission file created: formatted_submission_round10b_clean.txt\\n\")\n",
        "\n",
        "# --- Step 4: Validate and print ---\n",
        "def validate_submission_format_and_print(filename):\n",
        "    valid = True\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    if len(lines) != 8:\n",
        "        print(f\"❌ ERROR: Submission file should have exactly 8 lines, found {len(lines)}.\")\n",
        "        valid = False\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        num_values = line.count('-') + 1\n",
        "        expected = list(expected_dims.values())[i]\n",
        "        print(f\"F{i+1}: {line}  -->  {num_values} values (Expected: {expected})\")\n",
        "        if num_values != expected:\n",
        "            print(f\"❌ ERROR: Line {i+1} (F{i+1}) has wrong number of values.\")\n",
        "            valid = False\n",
        "\n",
        "    if valid:\n",
        "        print(\"\\n✅ Submission file passed all strict validation checks (8 lines, correct dimensions, clean format).\")\n",
        "    else:\n",
        "        print(\"\\n❌ Issues found. Please correct the file before submission.\")\n",
        "\n",
        "validate_submission_format_and_print(submission_file_10b_clean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awpp1QM66FMo",
        "outputId": "b209aa8a-f1f4-4df4-e24b-23257948d590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded clean, isolated datasets per function.\n",
            "\n",
            "✅ Submission file created: formatted_submission_round10b_clean.txt\n",
            "\n",
            "F1: 0.456851-0.079824  -->  2 values (Expected: 2)\n",
            "F2: 0.787800-0.035231  -->  2 values (Expected: 2)\n",
            "F3: 0.321450-0.823208-0.409574  -->  3 values (Expected: 3)\n",
            "F4: 0.350240-0.366425-0.396955-0.442771  -->  4 values (Expected: 4)\n",
            "F5: 0.712434-0.449440-0.225710-0.405942  -->  4 values (Expected: 4)\n",
            "F6: 0.638805-0.693836-0.473247-0.366139-0.482008  -->  5 values (Expected: 5)\n",
            "F7: 0.538231-0.530784-0.595488-0.620346-0.413495-0.619624  -->  6 values (Expected: 6)\n",
            "F8: 0.157267-0.128954-0.047746-0.033620-0.520267-0.741193-0.182530-0.458689  -->  8 values (Expected: 8)\n",
            "\n",
            "✅ Submission file passed all strict validation checks (8 lines, correct dimensions, clean format).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Round 11 Preparation\n",
        "\n",
        "**Strategy Type (Planned):** Advanced Iterative Optimization with Final Surrogate Refinement\n",
        "**Focus (Planned):** Leverage full Round 10 feedback to refine surrogates, enhance EI performance, enforce diversity, and finalize per-function strategies for the last rounds.\n",
        "**Planned Methods:**\n",
        "- **Retrain per-function surrogates using data from Rounds 0–10.**\n",
        "- **Expected Improvement (EI) acquisition and diversity clustering for F2–F6, F8.**\n",
        "- **Pure exploration with LHS and focused local sampling for F1, F7.**\n",
        "- **Dimensional validation enforced at every step.**\n",
        "\n",
        "### ✅ Next steps once Round 10 feedback arrives:\n",
        "1. **Ingest Round 10 feedback and append to historical datasets per function.**\n",
        "2. **Retrain surrogates for F1–F8 on the full data.**\n",
        "3. **Run updated function-specific candidate proposal pipeline.**\n",
        "4. **Validate and prepare final submission for Round 11.**\n",
        "\n",
        "---\n",
        "\n",
        "### Round 11 Observations Placeholder\n",
        "\n",
        "```python\n",
        "# Round 11 Observations Placeholder\n",
        "\n",
        "# F1\n",
        "queries_F1 = []\n",
        "scores_F1 = []\n",
        "\n",
        "# F2\n",
        "queries_F2 = []\n",
        "scores_F2 = []\n",
        "\n",
        "# F3\n",
        "queries_F3 = []\n",
        "scores_F3 = []\n",
        "\n",
        "# F4\n",
        "queries_F4 = []\n",
        "scores_F4 = []\n",
        "\n",
        "# F5\n",
        "queries_F5 = []\n",
        "scores_F5 = []\n",
        "\n",
        "# F6\n",
        "queries_F6 = []\n",
        "scores_F6 = []\n",
        "\n",
        "# F7\n",
        "queries_F7 = []\n",
        "scores_F7 = []\n",
        "\n",
        "# F8\n",
        "queries_F8 = []\n",
        "scores_F8 = []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "t8xaUpeN8b-U",
        "outputId": "5409186f-f0a7-45fc-dbcc-e743790e22b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '–' (U+2013) (<ipython-input-32-89028bb5baa2>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-89028bb5baa2>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    - **Retrain per-function surrogates using data from Rounds 0–10.**\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '–' (U+2013)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round 11 queries and scores\n",
        "round11_queries = [\n",
        "    [0.456851, 0.079824],  # F1\n",
        "    [0.7878, 0.035231],    # F2\n",
        "    [0.32145, 0.823208, 0.409574],  # F3\n",
        "    [0.35024, 0.366425, 0.396955, 0.442771],  # F4\n",
        "    [0.712434, 0.44944, 0.22571, 0.405942],  # F5\n",
        "    [0.638805, 0.693836, 0.473247, 0.366139, 0.482008],  # F6\n",
        "    [0.538231, 0.530784, 0.595488, 0.620346, 0.413495, 0.619624],  # F7\n",
        "    [0.157267, 0.128954, 0.047746, 0.03362, 0.520267, 0.741193, 0.18253, 0.458689]  # F8\n",
        "]\n",
        "\n",
        "round11_scores = [\n",
        "    -0.1459,   # F1\n",
        "    0.0337,    # F2\n",
        "    -0.0246,   # F3\n",
        "    0.2822,    # F4\n",
        "    13.3302,   # F5\n",
        "    -1.4710,   # F6\n",
        "    0.3841,    # F7\n",
        "    9.8592     # F8\n",
        "]\n",
        "\n",
        "# Initialize or update each function's queries and scores\n",
        "for i in range(8):\n",
        "    fn = f\"F{i+1}\"\n",
        "    globals()[f\"queries_{fn}\"] = globals().get(f\"queries_{fn}\", [])\n",
        "    globals()[f\"scores_{fn}\"]  = globals().get(f\"scores_{fn}\", [])\n",
        "    globals()[f\"queries_{fn}\"].append(round11_queries[i])\n",
        "    globals()[f\"scores_{fn}\"].append(round11_scores[i])"
      ],
      "metadata": {
        "id": "oISFyQO-vsrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1HJYFc2w1Bn",
        "outputId": "a6f5fe1b-458e-42ee-e73a-9285e5675d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cma\n",
            "  Downloading cma-4.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cma) (2.0.2)\n",
            "Downloading cma-4.0.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.5/283.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cma\n",
            "Successfully installed cma-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, qmc\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "\n",
        "# 1. Your historical data (queries_F1...F8, scores_F1...F8) should already be loaded and appended\n",
        "# 2. Define expected dimensions per function\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "\n",
        "# 3. EI acquisition function\n",
        "def suggest_ei(dim, X_hist, y_hist, n_suggest=1, samples=10000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=1.5) + WhiteKernel(noise_level=1e-6), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "# 4. Format vectors into the expected dash-separated string\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# 5. Generate submission for Round 11\n",
        "final_queries_round11 = []\n",
        "\n",
        "for i in range(1, 9):\n",
        "    func = f\"F{i}\"\n",
        "    dim = expected_dims[func]\n",
        "    X = np.array(globals()[f'queries_{func}'])\n",
        "    y = np.array(globals()[f'scores_{func}'])\n",
        "\n",
        "    if func in ['F1', 'F7']:\n",
        "        # Pure LHS\n",
        "        sample = qmc.LatinHypercube(d=dim).random(1)[0]\n",
        "        final_queries_round11.append(format_query(sample))\n",
        "    else:\n",
        "        # EI-guided\n",
        "        suggestion = suggest_ei(dim, X, y, n_suggest=1)\n",
        "        final_queries_round11.append(format_query(suggestion[0]))\n",
        "\n",
        "# 6. Save to text file\n",
        "with open(\"formatted_submission_round11.txt\", \"w\") as f:\n",
        "    for q in final_queries_round11:\n",
        "        f.write(q + '\\n')\n",
        "\n",
        "# 7. Display for verification\n",
        "for i, q in enumerate(final_queries_round11):\n",
        "    print(f\"F{i+1}: {q}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzX7ZI4ZxnYm",
        "outputId": "681c5c62-a33e-4f9f-aef4-1b2cb94a558d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.192884-0.926413\n",
            "F2: 0.005054-0.998337\n",
            "F3: 0.992182-0.084736-0.999894\n",
            "F4: 0.966750-0.982004-0.908933-0.873589\n",
            "F5: 0.064860-0.941199-0.990350-0.927245\n",
            "F6: 0.006714-0.013039-0.101960-0.868555-0.917215\n",
            "F7: 0.037117-0.034564-0.896005-0.769715-0.537417-0.940525\n",
            "F8: 0.982454-0.918714-0.621824-0.920226-0.973726-0.081911-0.932950-0.683774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, qmc\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "\n",
        "# --- Function metadata ---\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "\n",
        "# --- EI strategy ---\n",
        "def suggest_ei(dim, X_hist, y_hist, n_suggest=1, samples=10000):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=1.5) + WhiteKernel(noise_level=1e-6), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "# --- Helper to format vector into dash-separated string ---\n",
        "def format_query(vector):\n",
        "    return '-'.join([f\"{v:.6f}\" for v in vector])\n",
        "\n",
        "# --- Generate Round 11 queries ---\n",
        "final_queries_round11 = []\n",
        "\n",
        "for i in range(1, 9):\n",
        "    func = f\"F{i}\"\n",
        "    dim = expected_dims[func]\n",
        "    X = np.array(globals()[f'queries_{func}'])\n",
        "    y = np.array(globals()[f'scores_{func}'])\n",
        "\n",
        "    if func in ['F1', 'F7']:\n",
        "        # Latin Hypercube Sampling\n",
        "        sample = qmc.LatinHypercube(d=dim).random(1)[0]\n",
        "        final_queries_round11.append(format_query(sample))\n",
        "    else:\n",
        "        # EI-guided\n",
        "        suggestion = suggest_ei(dim, X, y, n_suggest=1)\n",
        "        final_queries_round11.append(format_query(suggestion[0]))\n",
        "\n",
        "# --- Save submission ---\n",
        "submission_file = \"formatted_submission_round11.txt\"\n",
        "with open(submission_file, \"w\") as f:\n",
        "    for q in final_queries_round11:\n",
        "        f.write(q + '\\n')\n",
        "\n",
        "# --- Validation ---\n",
        "print(f\"✅ Submission file '{submission_file}' created.\\n\")\n",
        "valid = True\n",
        "\n",
        "if len(final_queries_round11) != 8:\n",
        "    print(f\"❌ ERROR: Submission has {len(final_queries_round11)} lines (should be 8)\")\n",
        "    valid = False\n",
        "\n",
        "for i, line in enumerate(final_queries_round11):\n",
        "    func = f\"F{i+1}\"\n",
        "    dim_expected = expected_dims[func]\n",
        "    values = line.strip().split(\"-\")\n",
        "    if len(values) != dim_expected:\n",
        "        print(f\"❌ ERROR: F{i+1} has {len(values)} values (expected {dim_expected}) → {line}\")\n",
        "        valid = False\n",
        "    else:\n",
        "        print(f\"F{i+1}: {line} ✅ {dim_expected}D\")\n",
        "\n",
        "if valid:\n",
        "    print(\"\\n✅ All validation checks passed — submission is ready.\")\n",
        "else:\n",
        "    print(\"\\n❌ Submission has formatting or dimensionality issues. Fix before uploading.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4eDIWwIx5d8",
        "outputId": "179fb465-ca65-46f5-8831-2861f2d20f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submission file 'formatted_submission_round11.txt' created.\n",
            "\n",
            "F1: 0.091551-0.163071 ✅ 2D\n",
            "F2: 0.001379-0.994497 ✅ 2D\n",
            "F3: 0.992244-0.012868-0.880511 ✅ 3D\n",
            "F4: 0.988164-0.958607-0.987289-0.138835 ✅ 4D\n",
            "F5: 0.015062-0.991568-0.855815-0.961844 ✅ 4D\n",
            "F6: 0.194185-0.012652-0.001263-0.973034-0.976119 ✅ 5D\n",
            "F7: 0.953227-0.191686-0.726186-0.916246-0.443283-0.482373 ✅ 6D\n",
            "F8: 0.987211-0.999823-0.737463-0.988837-0.760353-0.175770-0.956319-0.602546 ✅ 8D\n",
            "\n",
            "✅ All validation checks passed — submission is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === ROUND 12 STRATEGY ===\n",
        "import numpy as np, scipy.stats.qmc as qmc\n",
        "from random import seed\n",
        "seed(42)\n",
        "\n",
        "def fmt(v): return \"-\".join([f\"{x:.6f}\" for x in v])\n",
        "\n",
        "# === Best vectors (from Round 10) ===\n",
        "best = {\n",
        "    \"F1\": np.array([0.944034, 0.625117]),  # needs explore\n",
        "    \"F2\": np.array([0.768771, 0.105777]),  # stable\n",
        "    \"F3\": np.array([0.145600, 0.944454, 0.638992]),\n",
        "    \"F4\": np.array([0.999363, 0.440618, 0.632742, 0.573562]),\n",
        "    \"F5\": np.array([0.290636, 0.824504, 0.580542, 0.368022]),\n",
        "    \"F6\": np.array([0.384874, 0.441523, 0.115493, 0.592513, 0.477029]),\n",
        "    \"F7\": np.array([0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193]),  # needs explore\n",
        "    \"F8\": np.array([0.236820, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776])\n",
        "}\n",
        "\n",
        "# === Candidate Generator ===\n",
        "def micro(vec, dim, delta):\n",
        "    v = vec.copy(); v[dim] += delta; return v\n",
        "def random_vec(dim):\n",
        "    return qmc.LatinHypercube(d=dim).random(1)[0]\n",
        "\n",
        "# === Candidates per function ===\n",
        "cands = []\n",
        "\n",
        "# F1 – 3 randoms + baseline\n",
        "for _ in range(3):\n",
        "    cands.append((\"F1\", random_vec(2)))\n",
        "cands.append((\"F1\", best[\"F1\"]))\n",
        "\n",
        "# F2–F5 – lock in best\n",
        "for fn in [\"F2\", \"F3\", \"F4\", \"F5\"]:\n",
        "    cands.append((fn, best[fn]))\n",
        "\n",
        "# F6 – baseline + +0.03 x₁ and +0.03 x₅\n",
        "cands += [\n",
        "    (\"F6\", best[\"F6\"]),\n",
        "    (\"F6\", micro(best[\"F6\"], 0, +0.03)),\n",
        "    (\"F6\", micro(best[\"F6\"], 4, +0.03))\n",
        "]\n",
        "\n",
        "# F7 – 3 Latin Hypercube randoms\n",
        "for _ in range(3):\n",
        "    cands.append((\"F7\", random_vec(6)))\n",
        "cands.append((\"F7\", best[\"F7\"]))\n",
        "\n",
        "# F8 – baseline + +0.03 x₁ and +0.03 x₂\n",
        "cands += [\n",
        "    (\"F8\", best[\"F8\"]),\n",
        "    (\"F8\", micro(best[\"F8\"], 0, +0.03)),\n",
        "    (\"F8\", micro(best[\"F8\"], 1, +0.03))\n",
        "]\n",
        "\n",
        "# === Export Files ===\n",
        "with open(\"formatted_submission.txt\", \"w\") as f:\n",
        "    chosen = {}\n",
        "    for fn, vec in cands:\n",
        "        if fn not in chosen:\n",
        "            chosen[fn] = vec\n",
        "    for i in range(1, 9):\n",
        "        f.write(fmt(chosen[f\"F{i}\"]) + \"\\n\")\n",
        "\n",
        "with open(\"candidate_review.txt\", \"w\") as f:\n",
        "    for i in range(1, 9):\n",
        "        fn = f\"F{i}\"\n",
        "        f.write(f\"{fn}:\\n\")\n",
        "        for idx, (f_tag, vec) in enumerate([c for c in cands if c[0] == fn]):\n",
        "            f.write(f\"cand{idx}: {fmt(vec)}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"✅ Round 12: Exported formatted_submission.txt and candidate_review.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ok9fQxX7nAOO",
        "outputId": "d199fb74-5e78-4516-8ad0-4adf689b5c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Round 12: Exported formatted_submission.txt and candidate_review.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd1dGOwixuy9",
        "outputId": "f227c2ef-19e5-441b-8de9-ea3641b3404a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/288.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m286.7/288.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm, qmc\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "import cma\n",
        "\n",
        "# --- Configuration ---\n",
        "expected_dims = {'F1': 2, 'F2': 2, 'F3': 3, 'F4': 4, 'F5': 4, 'F6': 5, 'F7': 6, 'F8': 8}\n",
        "N_SAMPLES = 10000\n",
        "K_TOP = 1\n",
        "\n",
        "# --- Strategy Functions ---\n",
        "def suggest_ei(X_hist, y_hist, dim, n_suggest=1, samples=N_SAMPLES):\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=2.5) + WhiteKernel(), normalize_y=True)\n",
        "    gp.fit(X_hist, y_hist)\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    X_cand = sampler.random(samples)\n",
        "    mu, sigma = gp.predict(X_cand, return_std=True)\n",
        "    best_y = np.max(y_hist)\n",
        "    z = (mu - best_y) / (sigma + 1e-9)\n",
        "    ei = (mu - best_y) * norm.cdf(z) + sigma * norm.pdf(z)\n",
        "    return X_cand[np.argsort(ei)[-n_suggest:]]\n",
        "\n",
        "def suggest_cma_es(gp, dim, sigma0=0.3, popsize=8, n_generations=20):\n",
        "    def fitness(x):\n",
        "        return -gp.predict(np.array(x).reshape(1, -1))[0]\n",
        "    x0 = np.random.uniform(0, 1, dim)\n",
        "    es = cma.CMAEvolutionStrategy(x0.tolist(), sigma0, {'popsize': popsize, 'bounds': [0, 1]})\n",
        "    es.optimize(fitness, iterations=n_generations)\n",
        "    return es.result.xbest\n",
        "\n",
        "def suggest_lhs(dim, n=1):\n",
        "    return qmc.LatinHypercube(d=dim).random(n)\n",
        "\n",
        "def fmt(vec):\n",
        "    return '-'.join([f\"{x:.6f}\" for x in vec])\n",
        "\n",
        "# --- Historical Data Input ---\n",
        "queries_dict = {\n",
        "    \"F1\": [\n",
        "        [0.944034, 0.625117],\n",
        "        [0.073140, 0.227123],\n",
        "        [0.944034, 0.645117],\n",
        "        [0.974034, 0.675117]\n",
        "    ],\n",
        "    \"F2\": [\n",
        "        [0.768771, 0.105777],\n",
        "        [0.778771, 0.105777],\n",
        "        [0.601115, 0.708072],\n",
        "        [0.712000, 0.489000]\n",
        "    ],\n",
        "    \"F3\": [\n",
        "        [0.145600, 0.944454, 0.638992],\n",
        "        [0.185600, 0.984454, 0.678992],\n",
        "        [0.175600, 0.974454, 0.658992],\n",
        "        [0.611852, 0.139493, 0.292144]\n",
        "    ],\n",
        "    \"F4\": [\n",
        "        [0.999363, 0.440618, 0.632742, 0.573562],\n",
        "        [0.989363, 0.430618, 0.632742, 0.583562],\n",
        "        [0.304613, 0.097672, 0.684233, 0.440152],\n",
        "        [0.726952, 0.189810, 0.835269, 0.100856]\n",
        "    ],\n",
        "    \"F5\": [\n",
        "        [0.290636, 0.824504, 0.580542, 0.368022],\n",
        "        [0.270636, 0.824504, 0.580542, 0.368022],\n",
        "        [0.088492, 0.195982, 0.045227, 0.325330],\n",
        "        [0.789315, 0.734624, 0.122222, 0.444444]\n",
        "    ],\n",
        "    \"F6\": [\n",
        "        [0.384874, 0.441523, 0.115493, 0.592513, 0.477029],\n",
        "        [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],\n",
        "        [0.433609, 0.430291, 0.199161, 0.583735, 0.454637],\n",
        "        [0.562398, 0.627903, 0.300000, 0.450000, 0.123456]\n",
        "    ],\n",
        "    \"F7\": [\n",
        "        [0.949760, 0.670137, 0.267596, 0.089014, 0.282662, 0.021611],\n",
        "        [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],\n",
        "        [0.334835, 0.585316, 0.860015, 0.467555, 0.862324, 0.768193],\n",
        "        [0.392748, 0.682337, 0.400000, 0.600000, 0.250000, 0.123000]\n",
        "    ],\n",
        "    \"F8\": [\n",
        "        [0.236820, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "        [0.256820, 0.180489, 0.295402, 0.830171, 0.672892, 0.287181, 0.913031, 0.782776],\n",
        "        [0.276820, 0.180489, 0.305402, 0.810171, 0.652892, 0.267181, 0.923031, 0.792776],\n",
        "        [0.688905, 0.968377, 0.100000, 0.200000, 0.300000, 0.400000, 0.500000, 0.600000]\n",
        "    ]\n",
        "}\n",
        "\n",
        "scores_dict = {\n",
        "    \"F1\": [\n",
        "        1.3276592050304897e-69,\n",
        "        4.6015626100136584e-113,\n",
        "        6.933250699386668e-70,\n",
        "        1.0331432167463326e-46\n",
        "    ],\n",
        "    \"F2\": [\n",
        "        0.27308818432797793,\n",
        "        0.09312933125476712,\n",
        "        0.33828687086483444,\n",
        "        0.5762427881544481\n",
        "    ],\n",
        "    \"F3\": [\n",
        "        -0.10726379301566011,\n",
        "        -0.05132522888449367,\n",
        "        -0.01882082499050317,\n",
        "        -0.14698930107649133\n",
        "    ],\n",
        "    \"F4\": [\n",
        "        -20.949420794091107,\n",
        "        -4.55517117590318,\n",
        "        -22.018089179607596,\n",
        "        0.28219639798857843\n",
        "    ],\n",
        "    \"F5\": [\n",
        "        13.377756436400528,\n",
        "        1105.1479642901527,\n",
        "        46.39060566194315,\n",
        "        13.330156169480178\n",
        "    ],\n",
        "    \"F6\": [\n",
        "        -1.1857272137575898,\n",
        "        -0.5399068214874156,\n",
        "        -1.0581335024921092,\n",
        "        -1.4710430538524402\n",
        "    ],\n",
        "    \"F7\": [\n",
        "        0.023506147714804363,\n",
        "        2.090579827192728,\n",
        "        1.5474127567590061,\n",
        "        0.38412848438494507\n",
        "    ],\n",
        "    \"F8\": [\n",
        "        8.3316420728934,\n",
        "        9.5659163853995,\n",
        "        8.316440887821,\n",
        "        9.8592499607924\n",
        "    ]\n",
        "}\n",
        "\n",
        "# --- Strategy Map per Function ---\n",
        "strategy_map = {\n",
        "    \"F1\": \"lhs\",\n",
        "    \"F2\": \"ei\",\n",
        "    \"F3\": \"ei\",\n",
        "    \"F4\": \"ei\",\n",
        "    \"F5\": \"best\",  # already optimal\n",
        "    \"F6\": \"ei+cma\",\n",
        "    \"F7\": \"lhs\",\n",
        "    \"F8\": \"ei+cma+lhs\"\n",
        "}\n",
        "\n",
        "final_queries = []\n",
        "review_queries = []\n",
        "\n",
        "for fn in [f\"F{i}\" for i in range(1, 9)]:\n",
        "    X = np.array(queries_dict[fn])\n",
        "    y = np.array(scores_dict[fn])\n",
        "    d = expected_dims[fn]\n",
        "    strat = strategy_map[fn]\n",
        "\n",
        "    if strat == \"lhs\":\n",
        "        sample = suggest_lhs(d, n=K_TOP)\n",
        "        final_queries.append(fmt(sample[0]))\n",
        "        review_queries.append((fn, sample[0]))\n",
        "\n",
        "    elif strat == \"ei\":\n",
        "        best = suggest_ei(X, y, d, n_suggest=K_TOP)\n",
        "        final_queries.append(fmt(best[0]))\n",
        "        review_queries.append((fn, best[0]))\n",
        "\n",
        "    elif strat == \"ei+cma\":\n",
        "        gp = GaussianProcessRegressor(kernel=Matern(nu=2.5) + WhiteKernel(), normalize_y=True)\n",
        "        gp.fit(X, y)\n",
        "        ei_vec = suggest_ei(X, y, d, n_suggest=1)[0]\n",
        "        cma_vec = suggest_cma_es(gp, d)\n",
        "        final_queries.append(fmt(ei_vec))\n",
        "        review_queries.extend([(fn, ei_vec), (fn, cma_vec)])\n",
        "\n",
        "    elif strat == \"ei+cma+lhs\":\n",
        "        gp = GaussianProcessRegressor(kernel=Matern(nu=2.5) + WhiteKernel(), normalize_y=True)\n",
        "        gp.fit(X, y)\n",
        "        ei_vec = suggest_ei(X, y, d, n_suggest=1)[0]\n",
        "        cma_vec = suggest_cma_es(gp, d)\n",
        "        lhs_vec = suggest_lhs(d, 1)[0]\n",
        "        final_queries.append(fmt(ei_vec))\n",
        "        review_queries.extend([(fn, ei_vec), (fn, cma_vec), (fn, lhs_vec)])\n",
        "\n",
        "    elif strat == \"best\":\n",
        "        best_idx = np.argmax(y)\n",
        "        best_vec = X[best_idx]\n",
        "        final_queries.append(fmt(best_vec))\n",
        "        review_queries.append((fn, best_vec))\n",
        "\n",
        "# --- Save Final Submission File ---\n",
        "with open(\"formatted_submission.txt\", \"w\") as f:\n",
        "    for q in final_queries:\n",
        "        f.write(q + \"\\n\")\n",
        "\n",
        "# --- Save Backup Candidates (Optional) ---\n",
        "with open(\"candidate_review.txt\", \"w\") as f:\n",
        "    for fn in sorted(set(f for f, _ in review_queries)):\n",
        "        f.write(f\"{fn}:\\n\")\n",
        "        count = 0\n",
        "        for f_tag, vec in review_queries:\n",
        "            if f_tag == fn:\n",
        "                f.write(f\"cand{count}: {fmt(vec)}\\n\")\n",
        "                count += 1\n",
        "        f.write(\"\\n\")\n",
        "with open(\"formatted_submission.txt\", \"r\") as f:\n",
        "    lines = [line.strip() for line in f.readlines()]\n",
        "    for i, line in enumerate(lines):\n",
        "        print(f\"F{i+1}: {line}\")\n",
        "print(\"✅ Round 13 files created: formatted_submission.txt + candidate_review.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTJkpwCnxDfn",
        "outputId": "4f4621df-fcb2-490d-d46a-8a58e2f813af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 5 (seed=362182, Mon May 26 04:09:50 2025)\n",
            "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
            "    1      8 1.063702647897389e+00 1.0e+00 2.51e-01  2e-01  3e-01 0:00.0\n",
            "(4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 8 (seed=257321, Mon May 26 04:09:51 2025)\n",
            "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
            "    1      8 -9.050075717069841e+00 1.0e+00 2.72e-01  3e-01  3e-01 0:00.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2     16 -9.138297502230099e+00 1.2e+00 2.57e-01  2e-01  3e-01 0:00.0\n",
            "    3     24 -9.225789659149898e+00 1.2e+00 2.58e-01  2e-01  3e-01 0:00.0\n",
            "F1: 0.879410-0.446353\n",
            "F2: 0.820170-0.854216\n",
            "F3: 0.179665-0.962743-0.643881\n",
            "F4: 0.381484-0.672193-0.109540-0.465085\n",
            "F5: 0.270636-0.824504-0.580542-0.368022\n",
            "F6: 0.253449-0.564709-0.522052-0.814941-0.923631\n",
            "F7: 0.221622-0.200272-0.950788-0.832244-0.934903-0.269186\n",
            "F8: 0.696464-0.988667-0.065271-0.356464-0.165350-0.435606-0.661504-0.499543\n",
            "✅ Round 13 files created: formatted_submission.txt + candidate_review.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load Round 13 Submission ===\n",
        "with open(\"formatted_submission.txt\", \"r\") as f:\n",
        "    new_queries = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# === Score Prediction and Comparison ===\n",
        "print(\"🔍 Evaluating accuracy of Round 13 submission vs past scores:\\n\")\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "import numpy as np\n",
        "\n",
        "for i in range(1, 9):\n",
        "    fn = f\"F{i}\"\n",
        "    dim = expected_dims[fn]\n",
        "\n",
        "    # Parse historical data\n",
        "    X = np.array(queries_dict[fn])\n",
        "    y = np.array(scores_dict[fn])\n",
        "\n",
        "    # Train surrogate model\n",
        "    gp = GaussianProcessRegressor(kernel=Matern(nu=2.5) + WhiteKernel(), normalize_y=True)\n",
        "    gp.fit(X, y)\n",
        "\n",
        "    # Parse new query\n",
        "    q_vec = np.array([float(x) for x in new_queries[i-1].split(\"-\")])\n",
        "    y_pred, y_std = gp.predict(q_vec.reshape(1, -1), return_std=True)\n",
        "\n",
        "    # Summary statistics\n",
        "    best = np.max(y)\n",
        "    mean = np.mean(y)\n",
        "    worst = np.min(y)\n",
        "\n",
        "    print(f\"{fn}:\")\n",
        "    print(f\"  🔢 Submitted vector: {new_queries[i-1]}\")\n",
        "    print(f\"  📈 Predicted Score: {y_pred[0]:.4f} ± {y_std[0]:.4f}\")\n",
        "    print(f\"  🥇 Best Past Score: {best:.4f}\")\n",
        "    print(f\"  📊 Average Score:   {mean:.4f}\")\n",
        "    print(f\"  🫠 Worst Past Score:{worst:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-Jike7qySG3",
        "outputId": "7ec32aa3-c453-44e6-b7f0-039676d416a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Evaluating accuracy of Round 13 submission vs past scores:\n",
            "\n",
            "F1:\n",
            "  🔢 Submitted vector: 0.879410-0.446353\n",
            "  📈 Predicted Score: 0.0000 ± 0.0000\n",
            "  🥇 Best Past Score: 0.0000\n",
            "  📊 Average Score:   0.0000\n",
            "  🫠 Worst Past Score:0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F2:\n",
            "  🔢 Submitted vector: 0.820170-0.854216\n",
            "  📈 Predicted Score: 0.3202 ± 0.1731\n",
            "  🥇 Best Past Score: 0.5762\n",
            "  📊 Average Score:   0.3202\n",
            "  🫠 Worst Past Score:0.0931\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F3:\n",
            "  🔢 Submitted vector: 0.179665-0.962743-0.643881\n",
            "  📈 Predicted Score: -0.0471 ± 0.0377\n",
            "  🥇 Best Past Score: -0.0188\n",
            "  📊 Average Score:   -0.0811\n",
            "  🫠 Worst Past Score:-0.1470\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F4:\n",
            "  🔢 Submitted vector: 0.381484-0.672193-0.109540-0.465085\n",
            "  📈 Predicted Score: -11.8101 ± 9.8399\n",
            "  🥇 Best Past Score: 0.2822\n",
            "  📊 Average Score:   -11.8101\n",
            "  🫠 Worst Past Score:-22.0181\n",
            "\n",
            "F5:\n",
            "  🔢 Submitted vector: 0.270636-0.824504-0.580542-0.368022\n",
            "  📈 Predicted Score: 294.5617 ± 568.0593\n",
            "  🥇 Best Past Score: 1105.1480\n",
            "  📊 Average Score:   294.5616\n",
            "  🫠 Worst Past Score:13.3302\n",
            "\n",
            "F6:\n",
            "  🔢 Submitted vector: 0.253449-0.564709-0.522052-0.814941-0.923631\n",
            "  📈 Predicted Score: -1.0637 ± 0.3376\n",
            "  🥇 Best Past Score: -0.5399\n",
            "  📊 Average Score:   -1.0637\n",
            "  🫠 Worst Past Score:-1.4710\n",
            "\n",
            "F7:\n",
            "  🔢 Submitted vector: 0.221622-0.200272-0.950788-0.832244-0.934903-0.269186\n",
            "  📈 Predicted Score: 1.2286 ± 0.8289\n",
            "  🥇 Best Past Score: 2.0906\n",
            "  📊 Average Score:   1.0114\n",
            "  🫠 Worst Past Score:0.0235\n",
            "\n",
            "F8:\n",
            "  🔢 Submitted vector: 0.696464-0.988667-0.065271-0.356464-0.165350-0.435606-0.661504-0.499543\n",
            "  📈 Predicted Score: 9.2809 ± 0.9177\n",
            "  🥇 Best Past Score: 9.8592\n",
            "  📊 Average Score:   9.0183\n",
            "  🫠 Worst Past Score:8.3164\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFJ_OvNfzAI-",
        "outputId": "b7a6b717-4662-4196-9e08-a3d163976263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cma in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cma) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace with your actual top F6 vectors\n",
        "top_f6_vectors = np.array([\n",
        "    [0.433609, 0.430291, 0.199161, 0.583735, 0.454637],\n",
        "    [0.414874, 0.421523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.460059, 0.426932, 0.132988, 0.650127, 0.537691],\n",
        "    [0.384874, 0.441523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],\n",
        "])"
      ],
      "metadata": {
        "id": "JoHz86FEp7JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossover(parent1, parent2):\n",
        "    alpha = np.random.uniform(0.3, 0.7)  # biased average\n",
        "    return alpha * parent1 + (1 - alpha) * parent2\n",
        "\n",
        "def mutate(vector, mutation_rate=0.1, std_dev=0.02):\n",
        "    if np.random.rand() < mutation_rate:\n",
        "        noise = np.random.normal(0, std_dev, size=vector.shape)\n",
        "        return np.clip(vector + noise, 0, 1)\n",
        "    return vector"
      ],
      "metadata": {
        "id": "5mwDqNdap-_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine original and new candidates\n",
        "new_candidates = evolve_population(top_f6_vectors, num_offspring=20)\n",
        "\n",
        "# Final submission list\n",
        "F6_submission_candidates = np.vstack((top_f6_vectors, new_candidates))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Hej2_rLVqCIm",
        "outputId": "487e7658-9394-407f-bdf1-ff1716201cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evolve_population' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bf2710c2ac47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Combine original and new candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolve_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_f6_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_offspring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Final submission list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mF6_submission_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_f6_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evolve_population' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# STEP 1: Top-performing F6 vectors — update these with your real data\n",
        "top_f6_vectors = np.array([\n",
        "    [0.433609, 0.430291, 0.199161, 0.583735, 0.454637],\n",
        "    [0.414874, 0.421523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.460059, 0.426932, 0.132988, 0.650127, 0.537691],\n",
        "    [0.384874, 0.441523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],\n",
        "])\n",
        "\n",
        "# STEP 2: Crossover — mix two parents\n",
        "def crossover(parent1, parent2):\n",
        "    alpha = np.random.uniform(0.3, 0.7)  # weighted mix\n",
        "    return alpha * parent1 + (1 - alpha) * parent2\n",
        "\n",
        "# STEP 3: Mutation — add small noise\n",
        "def mutate(vector, mutation_rate=0.2, std_dev=0.02):\n",
        "    if np.random.rand() < mutation_rate:\n",
        "        noise = np.random.normal(0, std_dev, size=vector.shape)\n",
        "        return np.clip(vector + noise, 0, 1)\n",
        "    return vector\n",
        "\n",
        "# STEP 4: Evolution — generate children\n",
        "def evolve_population(parents, num_offspring=20):\n",
        "    offspring = []\n",
        "    num_parents = len(parents)\n",
        "    while len(offspring) < num_offspring:\n",
        "        i, j = np.random.choice(num_parents, 2, replace=False)\n",
        "        child = crossover(parents[i], parents[j])\n",
        "        child = mutate(child)\n",
        "        offspring.append(child)\n",
        "    return np.array(offspring)\n",
        "\n",
        "# STEP 5: Generate candidates and prepare for submission\n",
        "new_candidates = evolve_population(top_f6_vectors, num_offspring=20)\n",
        "F6_submission_candidates = np.vstack((top_f6_vectors, new_candidates))"
      ],
      "metadata": {
        "id": "jbj_VDZNqLJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all F6 candidate vectors\n",
        "for i, vec in enumerate(F6_submission_candidates):\n",
        "    print(f\"Candidate {i+1}: {vec}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vjvUBc2qdyZ",
        "outputId": "15aa5500-7ab8-49fb-d45a-44a698b67d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate 1: [0.433609 0.430291 0.199161 0.583735 0.454637]\n",
            "Candidate 2: [0.414874 0.421523 0.115493 0.592513 0.477029]\n",
            "Candidate 3: [0.460059 0.426932 0.132988 0.650127 0.537691]\n",
            "Candidate 4: [0.384874 0.441523 0.115493 0.592513 0.477029]\n",
            "Candidate 5: [0.404874 0.441523 0.135493 0.612513 0.497029]\n",
            "Candidate 6: [0.41854205 0.4361804  0.16577723 0.5988245  0.47686488]\n",
            "Candidate 7: [0.41355452 0.43812994 0.15472638 0.60381949 0.48422286]\n",
            "Candidate 8: [0.41749694 0.43474283 0.14494444 0.61066265 0.4797329 ]\n",
            "Candidate 9: [0.39719717 0.441523   0.12781617 0.60483617 0.48935217]\n",
            "Candidate 10: [0.4517245  0.42799043 0.15383938 0.62920661 0.51152035]\n",
            "Candidate 11: [0.42651898 0.43580003 0.13451047 0.62726618 0.51297768]\n",
            "Candidate 12: [0.43571093 0.43165718 0.12732238 0.63146916 0.51804609]\n",
            "Candidate 13: [0.44813074 0.42844682 0.1628303  0.62018594 0.50023581]\n",
            "Candidate 14: [0.43594766 0.43330708 0.13408248 0.63369275 0.51992502]\n",
            "Candidate 15: [0.42101961 0.43521197 0.17126675 0.59634323 0.4732098 ]\n",
            "Candidate 16: [0.41518522 0.43453715 0.16753114 0.58705344 0.46310207]\n",
            "Candidate 17: [0.44730445 0.42855176 0.16489752 0.61811188 0.49764123]\n",
            "Candidate 18: [0.41137479 0.43541534 0.16098942 0.58773976 0.46485283]\n",
            "Candidate 19: [0.44902909 0.42833274 0.1605828  0.62244088 0.50305666]\n",
            "Candidate 20: [0.41135638 0.43541958 0.16095781 0.58774307 0.46486129]\n",
            "Candidate 21: [0.4257082  0.43601441 0.13454728 0.62671355 0.51238027]\n",
            "Candidate 22: [0.40657144 0.43652237 0.15274305 0.58860492 0.4670598 ]\n",
            "Candidate 23: [0.41495714 0.43568483 0.12249313 0.6155656  0.50130117]\n",
            "Candidate 24: [0.4114104 0.4284502 0.1224202 0.5994402 0.4839562]\n",
            "Candidate 25: [0.43645178 0.43317379 0.1340596  0.63403636 0.52029647]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**f6 best codadate round 13 **"
      ],
      "metadata": {
        "id": "ZD0GIK7Ar5by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Your 25 F6 candidate vectors\n",
        "F6_submission_candidates = np.array([\n",
        "    [0.433609, 0.430291, 0.199161, 0.583735, 0.454637],\n",
        "    [0.414874, 0.421523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.460059, 0.426932, 0.132988, 0.650127, 0.537691],\n",
        "    [0.384874, 0.441523, 0.115493, 0.592513, 0.477029],\n",
        "    [0.404874, 0.441523, 0.135493, 0.612513, 0.497029],\n",
        "    [0.41854205, 0.4361804, 0.16577723, 0.5988245, 0.47686488],\n",
        "    [0.41355452, 0.43812994, 0.15472638, 0.60381949, 0.48422286],\n",
        "    [0.41749694, 0.43474283, 0.14494444, 0.61066265, 0.4797329],\n",
        "    [0.39719717, 0.441523, 0.12781617, 0.60483617, 0.48935217],\n",
        "    [0.4517245, 0.42799043, 0.15383938, 0.62920661, 0.51152035],\n",
        "    [0.42651898, 0.43580003, 0.13451047, 0.62726618, 0.51297768],\n",
        "    [0.43571093, 0.43165718, 0.12732238, 0.63146916, 0.51804609],\n",
        "    [0.44813074, 0.42844682, 0.1628303, 0.62018594, 0.50023581],\n",
        "    [0.43594766, 0.43330708, 0.13408248, 0.63369275, 0.51992502],\n",
        "    [0.42101961, 0.43521197, 0.17126675, 0.59634323, 0.4732098],\n",
        "    [0.41518522, 0.43453715, 0.16753114, 0.58705344, 0.46310207],\n",
        "    [0.44730445, 0.42855176, 0.16489752, 0.61811188, 0.49764123],\n",
        "    [0.41137479, 0.43541534, 0.16098942, 0.58773976, 0.46485283],\n",
        "    [0.44902909, 0.42833274, 0.1605828, 0.62244088, 0.50305666],\n",
        "    [0.41135638, 0.43541958, 0.16095781, 0.58774307, 0.46486129],\n",
        "    [0.4257082, 0.43601441, 0.13454728, 0.62671355, 0.51238027],\n",
        "    [0.40657144, 0.43652237, 0.15274305, 0.58860492, 0.4670598],\n",
        "    [0.41495714, 0.43568483, 0.12249313, 0.6155656, 0.50130117],\n",
        "    [0.4114104, 0.4284502, 0.1224202, 0.5994402, 0.4839562],\n",
        "    [0.43645178, 0.43317379, 0.1340596, 0.63403636, 0.52029647]\n",
        "])\n",
        "\n",
        "# Simulated scoring function (tweak if needed)\n",
        "def mock_score(vec):\n",
        "    return round(\n",
        "        1\n",
        "        - abs(vec[3] - 0.63) * 2       # 4th dimension\n",
        "        - abs(vec[4] - 0.52) * 1.5     # 5th dimension\n",
        "        - abs(vec[2] - 0.13)          # 3rd dimension\n",
        "        - abs(vec[0] - 0.435) * 0.5   # 1st dimension (less sensitive)\n",
        "        , 6)\n",
        "\n",
        "# Score and print\n",
        "best_score = -1\n",
        "best_index = -1\n",
        "\n",
        "for i, vec in enumerate(F6_submission_candidates):\n",
        "    score = mock_score(vec)\n",
        "    print(f\"Candidate {i+1}: {vec} → Score: {score}\")\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_index = i\n",
        "\n",
        "# Print best candidate\n",
        "print(\"\\n🏆 Best Candidate to Submit:\")\n",
        "print(f\"Candidate {best_index+1}: {F6_submission_candidates[best_index]} → Score: {best_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODNcGfGprll1",
        "outputId": "099f32c0-5107-4f0a-dd42-0e1cb1d9dcb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate 1: [0.433609 0.430291 0.199161 0.583735 0.454637] → Score: 0.739569\n",
            "Candidate 2: [0.414874 0.421523 0.115493 0.592513 0.477029] → Score: 0.835999\n",
            "Candidate 3: [0.460059 0.426932 0.132988 0.650127 0.537691] → Score: 0.917692\n",
            "Candidate 4: [0.384874 0.441523 0.115493 0.592513 0.477029] → Score: 0.820999\n",
            "Candidate 5: [0.404874 0.441523 0.135493 0.612513 0.497029] → Score: 0.910014\n",
            "Candidate 6: [0.41854205 0.4361804  0.16577723 0.5988245  0.47686488] → Score: 0.82894\n",
            "Candidate 7: [0.41355452 0.43812994 0.15472638 0.60381949 0.48422286] → Score: 0.858524\n",
            "Candidate 8: [0.41749694 0.43474283 0.14494444 0.61066265 0.4797329 ] → Score: 0.877229\n",
            "Candidate 9: [0.39719717 0.441523   0.12781617 0.60483617 0.48935217] → Score: 0.882615\n",
            "Candidate 10: [0.4517245  0.42799043 0.15383938 0.62920661 0.51152035] → Score: 0.953492\n",
            "Candidate 11: [0.42651898 0.43580003 0.13451047 0.62726618 0.51297768] → Score: 0.975248\n",
            "Candidate 12: [0.43571093 0.43165718 0.12732238 0.63146916 0.51804609] → Score: 0.991098\n",
            "Candidate 13: [0.44813074 0.42844682 0.1628303  0.62018594 0.50023581] → Score: 0.91133\n",
            "Candidate 14: [0.43594766 0.43330708 0.13408248 0.63369275 0.51992502] → Score: 0.987946\n",
            "Candidate 15: [0.42101961 0.43521197 0.17126675 0.59634323 0.4732098 ] → Score: 0.814244\n",
            "Candidate 16: [0.41518522 0.43453715 0.16753114 0.58705344 0.46310207] → Score: 0.781321\n",
            "Candidate 17: [0.44730445 0.42855176 0.16489752 0.61811188 0.49764123] → Score: 0.901636\n",
            "Candidate 18: [0.41137479 0.43541534 0.16098942 0.58773976 0.46485283] → Score: 0.789957\n",
            "Candidate 19: [0.44902909 0.42833274 0.1605828  0.62244088 0.50305666] → Score: 0.921869\n",
            "Candidate 20: [0.41135638 0.43541958 0.16095781 0.58774307 0.46486129] → Score: 0.789998\n",
            "Candidate 21: [0.4257082  0.43601441 0.13454728 0.62671355 0.51238027] → Score: 0.972804\n",
            "Candidate 22: [0.40657144 0.43652237 0.15274305 0.58860492 0.4670598 ] → Score: 0.800842\n",
            "Candidate 23: [0.41495714 0.43568483 0.12249313 0.6155656  0.50130117] → Score: 0.925555\n",
            "Candidate 24: [0.4114104 0.4284502 0.1224202 0.5994402 0.4839562] → Score: 0.86544\n",
            "Candidate 25: [0.43645178 0.43317379 0.1340596  0.63403636 0.52029647] → Score: 0.986697\n",
            "\n",
            "🏆 Best Candidate to Submit:\n",
            "Candidate 12: [0.43571093 0.43165718 0.12732238 0.63146916 0.51804609] → Score: 0.991098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import qmc\n",
        "\n",
        "def micro_perturbations(base_vec, delta=0.01):\n",
        "    candidates = [base_vec]\n",
        "    for i in range(len(base_vec)):\n",
        "        plus = base_vec.copy()\n",
        "        minus = base_vec.copy()\n",
        "        plus[i] = min(1, plus[i] + delta)\n",
        "        minus[i] = max(0, minus[i] - delta)\n",
        "        candidates.extend([plus, minus])\n",
        "    return candidates\n",
        "\n",
        "def latin_hypercube_samples(dim, n_samples):\n",
        "    sampler = qmc.LatinHypercube(d=dim)\n",
        "    samples = sampler.random(n_samples)\n",
        "    return samples\n",
        "\n",
        "# Example base vectors (replace with your best known)\n",
        "best_F7 = np.array([0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193])\n",
        "best_F4 = np.array([0.999363, 0.440618, 0.632742, 0.573562])\n",
        "best_F8 = np.array([0.236820, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776])\n",
        "\n",
        "# Generate candidates\n",
        "F7_candidates = latin_hypercube_samples(dim=6, n_samples=10).tolist()\n",
        "F4_candidates = micro_perturbations(best_F4, delta=0.005)\n",
        "F8_candidates = micro_perturbations(best_F8[:2], delta=0.03)  # perturb first two dims\n",
        "# Combine with baseline for F8 full vector\n",
        "F8_candidates = [np.concatenate([c, best_F8[2:]]) if len(c) == 2 else c for c in F8_candidates]\n",
        "\n",
        "# Print sizes\n",
        "print(f\"Generated {len(F7_candidates)} candidates for Function 7\")\n",
        "print(f\"Generated {len(F4_candidates)} candidates for Function 4\")\n",
        "print(f\"Generated {len(F8_candidates)} candidates for Function 8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjgycA2_sIP9",
        "outputId": "5a212d11-9deb-41f8-a56f-6f9309265953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 10 candidates for Function 7\n",
            "Generated 9 candidates for Function 4\n",
            "Generated 5 candidates for Function 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Your actual candidate vectors for each function\n",
        "\n",
        "F7_candidates = np.array([\n",
        "    [0.304835, 0.615316, 0.890015, 0.497555, 0.892324, 0.798193],\n",
        "    [0.205, 0.625, 0.89, 0.5, 0.89, 0.8],\n",
        "    [0.31, 0.6, 0.88, 0.49, 0.9, 0.79],\n",
        "    [0.29, 0.62, 0.87, 0.51, 0.88, 0.81],\n",
        "    [0.32, 0.61, 0.89, 0.5, 0.9, 0.8],\n",
        "    [0.3, 0.62, 0.85, 0.5, 0.91, 0.77],\n",
        "    [0.31, 0.615, 0.9, 0.495, 0.88, 0.79],\n",
        "    [0.305, 0.61, 0.88, 0.505, 0.89, 0.8],\n",
        "    [0.3, 0.62, 0.89, 0.5, 0.9, 0.81],\n",
        "    [0.299, 0.613, 0.87, 0.498, 0.89, 0.79]\n",
        "])\n",
        "\n",
        "F4_candidates = np.array([\n",
        "    [0.999363, 0.440618, 0.632742, 0.573562],\n",
        "    [1.004, 0.445, 0.635, 0.57],\n",
        "    [0.995, 0.438, 0.63, 0.575],\n",
        "    [1.0, 0.44, 0.63, 0.57],\n",
        "    [0.999, 0.442, 0.631, 0.572],\n",
        "    [1.002, 0.439, 0.629, 0.571],\n",
        "    [0.998, 0.441, 0.633, 0.57],\n",
        "    [1.001, 0.44, 0.632, 0.573],\n",
        "    [0.997, 0.443, 0.63, 0.574]\n",
        "])\n",
        "\n",
        "F8_candidates = np.array([\n",
        "    [0.236820, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "    [0.266820, 0.190489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "    [0.206820, 0.130489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "    [0.236820, 0.130489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "    [0.236820, 0.190489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776]\n",
        "])\n",
        "\n",
        "# Mock scoring functions tuned to each function's sensitive dims\n",
        "\n",
        "def score_F7(vec):\n",
        "    return round(\n",
        "        1\n",
        "        - abs(vec[1] - 0.62) * 1.5\n",
        "        - abs(vec[2] - 0.89) * 2\n",
        "        - abs(vec[5] - 0.8) * 1.2\n",
        "        , 6)\n",
        "\n",
        "def score_F4(vec):\n",
        "    return round(\n",
        "        1\n",
        "        - abs(vec[0] - 0.999) * 5\n",
        "        - abs(vec[1] - 0.44) * 3\n",
        "        - abs(vec[2] - 0.63) * 2\n",
        "        , 6)\n",
        "\n",
        "def score_F8(vec):\n",
        "    return round(\n",
        "        1\n",
        "        - abs(vec[0] - 0.24) * 4\n",
        "        - abs(vec[1] - 0.16) * 4\n",
        "        - abs(vec[7] - 0.76) * 1\n",
        "        , 6)\n",
        "\n",
        "def evaluate_candidates(candidates, scoring_func, func_name):\n",
        "    scores = []\n",
        "    for i, vec in enumerate(candidates):\n",
        "        sc = scoring_func(vec)\n",
        "        scores.append((i+1, vec, sc))\n",
        "    scores.sort(key=lambda x: x[2], reverse=True)\n",
        "    print(f\"--- {func_name} ---\")\n",
        "    for c, v, s in scores:\n",
        "        print(f\"Candidate {c}: Score={s} Vector={v}\")\n",
        "    best = scores[0]\n",
        "    print(f\"Best candidate for {func_name}: Candidate {best[0]} with score {best[2]}\\n\")\n",
        "    return best\n",
        "\n",
        "# Run evaluations\n",
        "best_F7 = evaluate_candidates(F7_candidates, score_F7, \"Function 7\")\n",
        "best_F4 = evaluate_candidates(F4_candidates, score_F4, \"Function 4\")\n",
        "best_F8 = evaluate_candidates(F8_candidates, score_F8, \"Function 8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpzT923Dscqb",
        "outputId": "f9ce7ab4-9322-49f0-e32f-f3920e5129a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Function 7 ---\n",
            "Candidate 2: Score=0.9925 Vector=[0.205 0.625 0.89  0.5   0.89  0.8  ]\n",
            "Candidate 1: Score=0.990776 Vector=[0.304835 0.615316 0.890015 0.497555 0.892324 0.798193]\n",
            "Candidate 9: Score=0.988 Vector=[0.3  0.62 0.89 0.5  0.9  0.81]\n",
            "Candidate 5: Score=0.985 Vector=[0.32 0.61 0.89 0.5  0.9  0.8 ]\n",
            "Candidate 8: Score=0.965 Vector=[0.305 0.61  0.88  0.505 0.89  0.8  ]\n",
            "Candidate 7: Score=0.9605 Vector=[0.31  0.615 0.9   0.495 0.88  0.79 ]\n",
            "Candidate 4: Score=0.948 Vector=[0.29 0.62 0.87 0.51 0.88 0.81]\n",
            "Candidate 3: Score=0.938 Vector=[0.31 0.6  0.88 0.49 0.9  0.79]\n",
            "Candidate 10: Score=0.9375 Vector=[0.299 0.613 0.87  0.498 0.89  0.79 ]\n",
            "Candidate 6: Score=0.884 Vector=[0.3  0.62 0.85 0.5  0.91 0.77]\n",
            "Best candidate for Function 7: Candidate 2 with score 0.9925\n",
            "\n",
            "--- Function 4 ---\n",
            "Candidate 4: Score=0.995 Vector=[1.   0.44 0.63 0.57]\n",
            "Candidate 5: Score=0.992 Vector=[0.999 0.442 0.631 0.572]\n",
            "Candidate 1: Score=0.990847 Vector=[0.999363 0.440618 0.632742 0.573562]\n",
            "Candidate 7: Score=0.986 Vector=[0.998 0.441 0.633 0.57 ]\n",
            "Candidate 8: Score=0.986 Vector=[1.001 0.44  0.632 0.573]\n",
            "Candidate 9: Score=0.981 Vector=[0.997 0.443 0.63  0.574]\n",
            "Candidate 6: Score=0.98 Vector=[1.002 0.439 0.629 0.571]\n",
            "Candidate 3: Score=0.974 Vector=[0.995 0.438 0.63  0.575]\n",
            "Candidate 2: Score=0.95 Vector=[1.004 0.445 0.635 0.57 ]\n",
            "Best candidate for Function 4: Candidate 4 with score 0.995\n",
            "\n",
            "--- Function 8 ---\n",
            "Candidate 1: Score=0.982548 Vector=[0.23682  0.160489 0.275402 0.810171 0.652892 0.267181 0.893031 0.762776]\n",
            "Candidate 4: Score=0.86646 Vector=[0.23682  0.130489 0.275402 0.810171 0.652892 0.267181 0.893031 0.762776]\n",
            "Candidate 5: Score=0.862548 Vector=[0.23682  0.190489 0.275402 0.810171 0.652892 0.267181 0.893031 0.762776]\n",
            "Candidate 2: Score=0.767988 Vector=[0.26682  0.190489 0.275402 0.810171 0.652892 0.267181 0.893031 0.762776]\n",
            "Candidate 3: Score=0.74646 Vector=[0.20682  0.130489 0.275402 0.810171 0.652892 0.267181 0.893031 0.762776]\n",
            "Best candidate for Function 8: Candidate 1 with score 0.982548\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_submission = {\n",
        "    \"F1\": [\n",
        "        # Insert your best known vectors for F1 here\n",
        "        # Example placeholder:\n",
        "        [0.999999, 0.999999]\n",
        "    ],\n",
        "    \"F2\": [\n",
        "        # Best vectors for F2\n",
        "        # Example placeholder:\n",
        "        [0.994497, 0.105777]\n",
        "    ],\n",
        "    \"F3\": [\n",
        "        # Best vectors for F3\n",
        "        # Example placeholder:\n",
        "        [0.992244, 0.012868, 0.880511]\n",
        "    ],\n",
        "    \"F4\": [\n",
        "        [1.0, 0.44, 0.63, 0.57]  # Best candidate from recent test\n",
        "    ],\n",
        "    \"F5\": [\n",
        "        # Best vectors for F5\n",
        "        # Example placeholder:\n",
        "        [0.991568, 0.824504, 0.580542, 0.368022]\n",
        "    ],\n",
        "    \"F6\": [\n",
        "        [0.43571093, 0.43165718, 0.12732238, 0.63146916, 0.51804609]  # Best F6 vector\n",
        "    ],\n",
        "    \"F7\": [\n",
        "        [0.205, 0.625, 0.89, 0.5, 0.89, 0.8]  # Best candidate from recent test\n",
        "    ],\n",
        "    \"F8\": [\n",
        "        [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776]  # Best candidate\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "OqFDqX7esrTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_vector_for_submission(vec):\n",
        "    # Clip values between 0 and 0.999999 (or just below 1 to follow format)\n",
        "    clipped = [min(max(v, 0), 0.999999) for v in vec]\n",
        "    # Format each value with 6 decimals and ensure leading '0.'\n",
        "    formatted_values = [f\"{v:.6f}\" if v < 1 else \"0.999999\" for v in clipped]\n",
        "    # Join with dash separator\n",
        "    return \"-\".join(formatted_values)\n",
        "\n",
        "# Example: your best vectors for each function\n",
        "best_vectors = {\n",
        "    \"F1\": [0.999999, 0.999999],\n",
        "    \"F2\": [0.994497, 0.105777],\n",
        "    \"F3\": [0.992244, 0.012868, 0.880511],\n",
        "    \"F4\": [1.0, 0.44, 0.63, 0.57],\n",
        "    \"F5\": [0.991568, 0.824504, 0.580542, 0.368022],\n",
        "    \"F6\": [0.43571093, 0.43165718, 0.12732238, 0.63146916, 0.51804609],\n",
        "    \"F7\": [0.205, 0.625, 0.89, 0.5, 0.89, 0.8],\n",
        "    \"F8\": [0.23682, 0.160489, 0.275402, 0.810171, 0.652892, 0.267181, 0.893031, 0.762776],\n",
        "}\n",
        "\n",
        "# Format all functions for submission\n",
        "formatted_submission = {}\n",
        "for func, vec in best_vectors.items():\n",
        "    formatted_submission[func] = format_vector_for_submission(vec)\n",
        "\n",
        "# Print each formatted string for submission input\n",
        "for func, formatted_str in formatted_submission.items():\n",
        "    print(f\"{func}: {formatted_str}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg8XpkEDtdrX",
        "outputId": "6f4d0f19-c200-42ec-8f2d-512be886a8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1: 0.999999-0.999999\n",
            "F2: 0.994497-0.105777\n",
            "F3: 0.992244-0.012868-0.880511\n",
            "F4: 0.999999-0.440000-0.630000-0.570000\n",
            "F5: 0.991568-0.824504-0.580542-0.368022\n",
            "F6: 0.435711-0.431657-0.127322-0.631469-0.518046\n",
            "F7: 0.205000-0.625000-0.890000-0.500000-0.890000-0.800000\n",
            "F8: 0.236820-0.160489-0.275402-0.810171-0.652892-0.267181-0.893031-0.762776\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}